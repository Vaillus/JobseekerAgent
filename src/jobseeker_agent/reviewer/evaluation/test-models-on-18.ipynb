{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf75652",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = r\"\"\"\n",
    "You are an expert in job-candidates matching.\n",
    "From the job description: {job_description}, \n",
    "company name: {company_name},\n",
    "job title: {job_title},\n",
    "and location: {location},\n",
    "and my profil: {profil_pro},\n",
    "\n",
    "Identify which of the following criteria are met by the job description:\n",
    "\n",
    "## The Job\n",
    "### Required expertise\n",
    "- Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill: (+2)\n",
    "- Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP): (+2)\n",
    "- Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job: (+2), +1 more if a large part of the job is dedicated to this.\n",
    "- Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences: (-2 if this domain/tool is central to the role, defined as being in the job title, company name, or a primary responsibility/requirement; -1 if it is a secondary qualification).\n",
    "- Requires a programming language I am not familiar with, AND does not mention Python: (-1)\n",
    "- More focused on infrastructure (databases, cloud, Docker) than on algorithms: (-3)\n",
    "- Vague description of actual tasks for a data scientist/engineer job: (-1)\n",
    "- 'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps): (-3)\n",
    "- 'optimization' mentioned primarily in the context of quantum algorithms: (-4)\n",
    "- The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified. : (+0.5)\n",
    "- Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (beyond just \"good fundamentals\" or \"being comfortable\"): (-1)\n",
    "- Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD): (+1.5)\n",
    "- Does not mention a PhD but requires experience doing research: (+1)\n",
    "### Type of role\n",
    "- More managerial than technical role: (-2)\n",
    "- Involves leading a team of highly qualified/experienced people (junior excluded): (-1) In a domain I am not familiar with: (-1)\n",
    "- Involves coaching world-class scientists: (-2)\n",
    "\n",
    "## The Company\n",
    "- Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia): (+2) (Do not trust the description of the company in the job description for this criteria, but your prior knowledge about the company if any.)\n",
    "- More than 150 employees: (-1)\n",
    "- Offers a full-remote option: (+2)\n",
    "- Consulting job for a standard/low-tier consulting firm: (-2)\n",
    "- In the defense sector: (+2)\n",
    "- In the robotics sector: (+2)\n",
    "- If not french, requires security clearance: (-1.5)\n",
    "\n",
    "^ only mention the lines that are relevant to the job description, with associated score bonus or penalty. \n",
    "For example, do not output \"- Leading a team: No (+0)\". Instead do not output anything for this criteria.\n",
    "For each line that is present in the result, mention the sentence/line that satisfies the criteria..\n",
    "Use strictly the elements above for score computation, not the synthesis below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4170fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobseeker_agent.utils.paths import load_prompt, load_full_job\n",
    "\n",
    "profil_pro = load_prompt(\"profil_pro\")\n",
    "job_id = 18\n",
    "job = load_full_job(job_id)\n",
    "job_description = job[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be1ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 18,\n",
       " 'title': 'Applied ML/AI Engineer - Monitoring',\n",
       " 'company': 'Sifflet',\n",
       " 'location': 'Paris, Île-de-France, France',\n",
       " 'job_link': 'https://fr.linkedin.com/jobs/view/applied-ml-ai-engineer-monitoring-at-sifflet-4314688170',\n",
       " 'posted_date': '2025-10-14',\n",
       " 'status': 'Open',\n",
       " 'workplace_type': 'Remote',\n",
       " 'description': \"**About Sifflet  \\n  \\n** We are building the world’s best data observability platform to help\\ncompanies excel at data-driven decision making.  \\n  \\nToday, half of a data team’s time is spent troubleshooting data quality\\nissues. Sifflet is putting an end to that. Our solution allows data engineers\\nand data consumers to visualize how data flows between their services, define\\ndata quality checks, and quickly find the root cause of any data anomaly.  \\n  \\n**About The Job  \\n  \\n** The monitoring team implements the foundational capabilities of Sifflet:\\ndetecting data quality issues across a wide range of data warehouses and\\ndatabases.  \\n  \\nSifflet's monitoring capabilities rely heavily on machine learning (ML)\\ntechniques. Most advanced data quality checks are based on time series\\nforecasting models that detect unexpected distribution changes while\\naccounting for seasonality and one-off events. Additionally, ML-based features\\nare present throughout our product, be it for intelligent alert grouping,\\nautomated incident description, or automated monitor suggestions.  \\n  \\nAs a machine learning engineer on the monitoring team, you will:  \\n  \\n\\n  * Build automated data profiling systems that learn normal data patterns and detect deviations.\\n  * Deploy time series forecasting models that understand data seasonality and business cycles.\\n  * Create intelligent alerting systems that reduce noise through ML-powered incident correlation.\\n  * Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\\n  * Contribute to product decisions and identify areas where adding ML/AI-based features can solve customer pain points.  \\n  \\n\\nAs we’re a small team, you will be expected to design, implement, deploy and\\nmaintain your projects in production, and integrate them with other services.\\nThus, this role includes a significant software engineering component.  \\n  \\nSome projects you could be working on  \\n  \\n\\n  * Automated monitor recommendations based on data profiling metrics.\\n  * Automated root cause analysis of any data quality incident, building upon the many sources of metadata Sifflet collects (table lineage, query history, past monitor failures…).  \\n  \\n\\nOur stack  \\n  \\n\\n  * The monitoring engine is built with Python 3 and its large data/ML ecosystem (notably PyTorch).\\n  * The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript. You may occasionally need to make minor changes to this code base.\\n  * Infrastructure: Kubernetes (AWS EKS clusters), MySQL (on AWS RDS), Temporal for job orchestration\\n  * Plus a few supporting services: Gitlab CI, Prometheus/Loki/Grafana, Sentry…  \\n  \\n\\nWhile not directly part of our stack, expect to gain a lot of knowledge on\\nmany products in the modern data ecosystem. The subtleties of BigQuery or\\nSnowflake will soon be very familiar to you.  \\n  \\nAre we the company you’re looking for?  \\n  \\n\\n  * We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\\n  * We offer competitive salary and company equity.\\n  * We have experts on many topics, so there’s always someone to help. We also have tech talks where everyone can discuss a cool project or technology.\\n  * We’re constantly exposed to the intricacies of the modern data ecosystem - you’ll become very knowledgeable about data engineering and the modern data stack, and about how data is used in enterprises.\\n  * Our culture emphasises teamwork to efficiently deliver projects to production.\\n  * We’re building a genuinely great product, and we think you’ll love the team!\\n  * More than three years of experience in a ML engineer role or equivalent. Hands-on production experience is appreciated.\\n  * General knowledge of the “modern data stack” ecosystem, especially data warehouses and databases. You don’t have to know everything upfront of course, you’ll pick up what you need on the job.\\n  * Experience with the Python ML ecosystem.\\n  * You value ownership of your projects from design to production, and aren’t afraid of taking initiatives.  \\n  \\n\\nAll written communication at Sifflet is in English, but the engineering team\\nroutinely uses French, so some level of fluency in French is required.  \\n  \\nNone of the people who joined Sifflet perfectly matched the described\\nrequirements for the role. If you’re interested in this position but don’t\\ntick all the boxes above, feel free to apply anyway!  \\n  \\n\\n  * A first call with either Benoît (Head of Engineering) or Pierre (Monitoring Team Lead) (30 minutes)\\n  * One coding interview and one system design interview (1h30 each)\\n  * One call with a product manager (30 minutes)  \\n  \\n\\nAt this point we generally know if we want to extend an offer, but we're happy\\nto organize additional sessions so you can better know the team and the\\ncompany.\\n\\nShow more  Show less\\n\\n\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f98b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**About Sifflet  \n",
      "  \n",
      "** We are building the world’s best data observability platform to help\n",
      "companies excel at data-driven decision making.  \n",
      "  \n",
      "Today, half of a data team’s time is spent troubleshooting data quality\n",
      "issues. Sifflet is putting an end to that. Our solution allows data engineers\n",
      "and data consumers to visualize how data flows between their services, define\n",
      "data quality checks, and quickly find the root cause of any data anomaly.  \n",
      "  \n",
      "**About The Job  \n",
      "  \n",
      "** The monitoring team implements the foundational capabilities of Sifflet:\n",
      "detecting data quality issues across a wide range of data warehouses and\n",
      "databases.  \n",
      "  \n",
      "Sifflet's monitoring capabilities rely heavily on machine learning (ML)\n",
      "techniques. Most advanced data quality checks are based on time series\n",
      "forecasting models that detect unexpected distribution changes while\n",
      "accounting for seasonality and one-off events. Additionally, ML-based features\n",
      "are present throughout our product, be it for intelligent alert grouping,\n",
      "automated incident description, or automated monitor suggestions.  \n",
      "  \n",
      "As a machine learning engineer on the monitoring team, you will:  \n",
      "  \n",
      "\n",
      "  * Build automated data profiling systems that learn normal data patterns and detect deviations.\n",
      "  * Deploy time series forecasting models that understand data seasonality and business cycles.\n",
      "  * Create intelligent alerting systems that reduce noise through ML-powered incident correlation.\n",
      "  * Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\n",
      "  * Contribute to product decisions and identify areas where adding ML/AI-based features can solve customer pain points.  \n",
      "  \n",
      "\n",
      "As we’re a small team, you will be expected to design, implement, deploy and\n",
      "maintain your projects in production, and integrate them with other services.\n",
      "Thus, this role includes a significant software engineering component.  \n",
      "  \n",
      "Some projects you could be working on  \n",
      "  \n",
      "\n",
      "  * Automated monitor recommendations based on data profiling metrics.\n",
      "  * Automated root cause analysis of any data quality incident, building upon the many sources of metadata Sifflet collects (table lineage, query history, past monitor failures…).  \n",
      "  \n",
      "\n",
      "Our stack  \n",
      "  \n",
      "\n",
      "  * The monitoring engine is built with Python 3 and its large data/ML ecosystem (notably PyTorch).\n",
      "  * The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript. You may occasionally need to make minor changes to this code base.\n",
      "  * Infrastructure: Kubernetes (AWS EKS clusters), MySQL (on AWS RDS), Temporal for job orchestration\n",
      "  * Plus a few supporting services: Gitlab CI, Prometheus/Loki/Grafana, Sentry…  \n",
      "  \n",
      "\n",
      "While not directly part of our stack, expect to gain a lot of knowledge on\n",
      "many products in the modern data ecosystem. The subtleties of BigQuery or\n",
      "Snowflake will soon be very familiar to you.  \n",
      "  \n",
      "Are we the company you’re looking for?  \n",
      "  \n",
      "\n",
      "  * We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\n",
      "  * We offer competitive salary and company equity.\n",
      "  * We have experts on many topics, so there’s always someone to help. We also have tech talks where everyone can discuss a cool project or technology.\n",
      "  * We’re constantly exposed to the intricacies of the modern data ecosystem - you’ll become very knowledgeable about data engineering and the modern data stack, and about how data is used in enterprises.\n",
      "  * Our culture emphasises teamwork to efficiently deliver projects to production.\n",
      "  * We’re building a genuinely great product, and we think you’ll love the team!\n",
      "  * More than three years of experience in a ML engineer role or equivalent. Hands-on production experience is appreciated.\n",
      "  * General knowledge of the “modern data stack” ecosystem, especially data warehouses and databases. You don’t have to know everything upfront of course, you’ll pick up what you need on the job.\n",
      "  * Experience with the Python ML ecosystem.\n",
      "  * You value ownership of your projects from design to production, and aren’t afraid of taking initiatives.  \n",
      "  \n",
      "\n",
      "All written communication at Sifflet is in English, but the engineering team\n",
      "routinely uses French, so some level of fluency in French is required.  \n",
      "  \n",
      "None of the people who joined Sifflet perfectly matched the described\n",
      "requirements for the role. If you’re interested in this position but don’t\n",
      "tick all the boxes above, feel free to apply anyway!  \n",
      "  \n",
      "\n",
      "  * A first call with either Benoît (Head of Engineering) or Pierre (Monitoring Team Lead) (30 minutes)\n",
      "  * One coding interview and one system design interview (1h30 each)\n",
      "  * One call with a product manager (30 minutes)  \n",
      "  \n",
      "\n",
      "At this point we generally know if we want to extend an offer, but we're happy\n",
      "to organize additional sessions so you can better know the team and the\n",
      "company.\n",
      "\n",
      "Show more  Show less\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fd2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Dict, Union\n",
    "\n",
    "class Evaluation(TypedDict):\n",
    "    \"\"\"Evaluation of the job description.\"\"\"\n",
    "    criteria: Annotated[str, ..., \"The criteria that are met by the job description.\"]\n",
    "    evidence: Annotated[str, ..., \"The evidence for the criteria that are met by the job description.\"]\n",
    "    score: Annotated[float, ..., \"The score for the criteria that are met by the job description.\"]\n",
    "\n",
    "class JobReviewResponse(TypedDict):\n",
    "    \"\"\"Response structure for job review.\"\"\"\n",
    "    evaluation_grid: Annotated[List[Evaluation], ..., \"List of evaluations for each relevant evaluation criterion\"]\n",
    "    score: Annotated[float, ..., \"raw score computed from the evaluation grid. Can be negative.\"]\n",
    "\n",
    "class JobReviewCorrectionResponse(TypedDict):\n",
    "    \"\"\"Response structure for job review correction.\"\"\"\n",
    "    correction: Annotated[str, ..., \"Correction of the evaluation grid.\"]\n",
    "    evaluation_grid: Annotated[List[Evaluation], ..., \"List of evaluations for each relevant evaluation criterion\"]\n",
    "    score: Annotated[float, ..., \"raw score computed from the evaluation grid. Can be negative.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad835df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobseeker_agent.utils.llm import get_llm\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import json\n",
    "def review(model, job_description, job_title, company_name, location, with_correction=False):\n",
    "    llm = get_llm(model)\n",
    "    llm = llm.with_structured_output(JobReviewResponse)\n",
    "    message = HumanMessage(\n",
    "        content=review_prompt.format(job_description=job_description, profil_pro=profil_pro, job_title=job_title, company_name=company_name, location=location)\n",
    "    )\n",
    "    response = llm.invoke([message])\n",
    "    if with_correction:\n",
    "        messages = [\n",
    "            message,\n",
    "            AIMessage(content=json.dumps(response)),\n",
    "            HumanMessage(content=\"Please correct the evaluation grid. Evaluate each element. Is it correct ? Are there any missing element ? If elements are removed from the evaluation grid, don't put them in the evaluation grid.\")\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54c016",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "review() missing 4 required positional arguments: 'job_description', 'job_title', 'company_name', and 'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m model = \u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_correction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# print the dict in easy to read format\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# print(json.dumps(result, indent=4))\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: review() missing 4 required positional arguments: 'job_description', 'job_title', 'company_name', and 'location'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "model = \"gpt-4o\"\n",
    "result = review(model, job_description, job_title, company_name, location, with_correction=True)\n",
    "print(result[\"score\"])\n",
    "# print the dict in easy to read format\n",
    "# print(json.dumps(result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6871af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761664652.990170 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"evaluation_grid\": [\n",
      "        {\n",
      "            \"criteria\": \"Heavily features agentic workflows (ie. langchain, tool use, prompt engineering, etc.)\",\n",
      "            \"evidence\": \"Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\",\n",
      "            \"score\": 3.0\n",
      "        },\n",
      "        {\n",
      "            \"criteria\": \"Requires a programming language I am not familiar with (and not Python)\",\n",
      "            \"evidence\": \"The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript. You may occasionally need to make minor changes to this code base.\",\n",
      "            \"score\": -1.0\n",
      "        },\n",
      "        {\n",
      "            \"criteria\": \"The job is based in France and requires a good english level\",\n",
      "            \"evidence\": \"We have offices in Paris, but we\\u2019re very remote friendly - several team members are fully remote. All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\",\n",
      "            \"score\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"criteria\": \"Offers a full-remote option\",\n",
      "            \"evidence\": \"We have offices in Paris, but we\\u2019re very remote friendly - several team members are fully remote.\",\n",
      "            \"score\": 2.0\n",
      "        }\n",
      "    ],\n",
      "    \"score\": 4.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-flash\"\n",
    "result = review(model)\n",
    "\n",
    "# print the dict in easy to read format\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d52028e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-4o\n",
      "✅ Chargement du modèle OpenAI : gpt-4o\n",
      "✅ Chargement du modèle OpenAI : gpt-5-nano\n",
      "✅ Chargement du modèle OpenAI : gpt-5-nano\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "models = [\"gpt-4.1\", \"gpt-4o\", \"gpt-5-nano\", \"gpt-5-mini\", \"gpt-5\"]\n",
    "responses = []\n",
    "corrections = [True, False]\n",
    "for model in models:\n",
    "    for correction in corrections:\n",
    "        start_time = time.time()\n",
    "        response = review(model, correction)\n",
    "        end_time = time.time()\n",
    "        response[\"model\"] = model\n",
    "        response[\"time\"] = end_time - start_time\n",
    "        response[\"correction\"] = correction\n",
    "        responses.append(response)\n",
    "\n",
    "# print the dict in easy to read format\n",
    "# print(json.dumps(responses, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "641dcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_responses = responses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0312b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761729285.206628 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "models = [\"gemini-2.5-flash\"]\n",
    "google_responses = []\n",
    "corrections = [False]\n",
    "for model in models:\n",
    "    for correction in corrections:\n",
    "        start_time = time.time()\n",
    "        response = review(model, correction)\n",
    "        end_time = time.time()\n",
    "        response[\"model\"] = model\n",
    "        response[\"time\"] = end_time - start_time\n",
    "        response[\"correction\"] = correction\n",
    "        google_responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a2c69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model  correction  score       time\n",
      "0  gemini-2.5-flash       False    4.5  35.850183\n"
     ]
    }
   ],
   "source": [
    "# show a table with score, time and model\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(google_responses)\n",
    "df = df[[\"model\", \"correction\", \"score\", \"time\"]]\n",
    "# print(df[df[\"score\"] ==4.5])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09338d",
   "metadata": {},
   "source": [
    "Les deux meilleurs modèles sont gpt-4.1 avec correction et gpt-5-mini sans correction.\n",
    "Le premier met quasi 2x moins de temps que le second. Du coup pour l'instant il gagne.\n",
    "à voir quels sont "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11422973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________\n",
      "GPT-4.1\n",
      "[{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill', 'evidence': 'The job description does not mention Reinforcement Learning (RL) anywhere.', 'score': 0}, {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)', 'evidence': 'There is no explicit mention of algorithmic/mathematical optimization, Operations Research, or related terms in the job description.', 'score': 0}, {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job', 'evidence': \"The job description mentions 'Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.' This suggests some involvement with prompt engineering and generative AI workflows, but does not explicitly mention agentic workflows or frameworks like LangChain.\", 'score': 2}, {'criteria': 'Requires strong expertise in a topic/domain I am not familiar with', 'evidence': 'The required expertise is in Python ML ecosystem, time series, and data engineering. These are within your skill set. No penalty.', 'score': 0}, {'criteria': 'Requires a programming language I am not familiar with, AND does not mention Python', 'evidence': 'Python 3 is the main language for the monitoring engine. Java is used for the web API, but Python is primary for ML. No penalty.', 'score': 0}, {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms', 'evidence': 'The job is focused on building ML-based monitoring and alerting systems, not primarily on infrastructure. Infrastructure is mentioned as part of the stack, but not as the main focus.', 'score': 0}, {'criteria': 'Vague description of actual tasks for a data scientist/engineer job', 'evidence': 'The job description is quite specific about the tasks: building data profiling systems, deploying time series models, creating alerting systems, etc.', 'score': 0}, {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\", 'evidence': 'Optimization is not mentioned in this context.', 'score': 0}, {'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms\", 'evidence': 'Quantum algorithms are not mentioned.', 'score': 0}, {'criteria': 'The job is based in France and requires a good english level', 'evidence': 'The job is based in France (Paris office) and requires English for written communication.', 'score': 0.5}, {'criteria': 'Offers a full-remote option', 'evidence': \"The job description says: 'We have offices in Paris, but we’re very remote friendly - several team members are fully remote.'\", 'score': 2}, {'criteria': 'Requires lots of experience in large scale training/inference/MLOps', 'evidence': 'There is no mention of large scale training/inference/MLOps as a requirement.', 'score': 0}, {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)', 'evidence': 'A PhD is not mentioned as a requirement or a plus.', 'score': 0}, {'criteria': 'More managerial than technical role', 'evidence': 'The role is technical, not managerial.', 'score': 0}, {'criteria': 'Involves leading a team of highly qualified/experienced people (junior excluded)', 'evidence': 'No mention of team leadership responsibilities.', 'score': 0}, {'criteria': 'Involves coaching world-class scientists', 'evidence': 'No mention of coaching world-class scientists.', 'score': 0}, {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)', 'evidence': 'Sifflet is not a top-tier company as defined here.', 'score': 0}, {'criteria': 'More than 150 employees', 'evidence': 'The company size is not specified, but Sifflet is described as a small team. No penalty.', 'score': 0}, {'criteria': 'Consulting job for a standard/low-tier consulting firm', 'evidence': 'Not a consulting job.', 'score': 0}, {'criteria': 'In the defense sector', 'evidence': 'Not in the defense sector.', 'score': 0}, {'criteria': 'In the robotics sector', 'evidence': 'Not in the robotics sector.', 'score': 0}, {'criteria': 'If not french, requires security clearance', 'evidence': 'No mention of security clearance.', 'score': 0}]\n",
      "____________\n",
      "GPT-5-MINI\n",
      "[{'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job (+2)', 'evidence': '\"Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\"', 'score': 2}, {'criteria': 'The job is based in France and requires a good english level (+0.5)', 'evidence': '\"We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\"; \"All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\"', 'score': 0.5}, {'criteria': 'Offers a full-remote option (+2)', 'evidence': '\"We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\"', 'score': 2}]\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "    if response[\"model\"] == \"gpt-4.1\" and response[\"correction\"]:\n",
    "        print(\"____________\")\n",
    "        print(response[\"model\"].upper())\n",
    "        print(response[\"correction\"])\n",
    "    if response[\"model\"] == \"gpt-5-mini\" and not response[\"correction\"]:\n",
    "        print(\"____________\")\n",
    "        print(response[\"model\"].upper())\n",
    "        print(response[\"correction\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e56ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________\n",
      "GPT-4O\n",
      "The job is based in France and requires a good English level\n",
      "\"All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\"\n",
      "Offers a full-remote option\n",
      "\"We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\"\n",
      "Requires a PhD in a field close to mine (or even if it is just a plus)\n",
      "\"More than three years of experience in a ML engineer role or equivalent. Hands-on production experience is appreciated.\"\n",
      "Requires a programming language I am not familiar with (and not Python)\n",
      "\"The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript.\"\n",
      "Requires strong expertise in a topic/domain I am not familiar with\n",
      "\"Sifflet's monitoring capabilities rely heavily on machine learning (ML) techniques. Most advanced data quality checks are based on time series forecasting models.\"\n",
      "More focused on infrastructure (databases, cloud, Docker) than on algorithms\n",
      "\"Infrastructure: Kubernetes (AWS EKS clusters), MySQL (on AWS RDS), Temporal for job orchestration.\"\n",
      "____________\n",
      "GPT-5-MINI\n",
      "Heavily features agentic workflows (ie. langchain, tool use, prompt engineering, etc.): (+3)\n",
      "Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\n",
      "The job is based in France and requires a good english level: (+0.5)\n",
      "We have offices in Paris, but we’re very remote friendly ... All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\n",
      "Offers a full-remote option: (+2)\n",
      "We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\n",
      "____________\n",
      "GPT-5\n",
      "Offers a full-remote option\n",
      "\"We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\"\n",
      "The job is based in France and requires a good english level\n",
      "\"We have offices in Paris...\" and \"All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\"\n",
      "____________\n",
      "GEMINI-2.5-FLASH\n",
      "Heavily features agentic workflows (ie. langchain, tool use, prompt engineering, etc.)\n",
      "Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\n",
      "Requires a programming language I am not familiar with (and not Python)\n",
      "The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript. You may occasionally need to make minor changes to this code base.\n",
      "The job is based in France and requires a good english level\n",
      "We have offices in Paris, but we’re very remote friendly - several team members are fully remote. All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\n",
      "Requires lots of experience in large scale training/inference/MLOps\n",
      "As we’re a small team, you will be expected to design, implement, deploy and maintain your projects in production, and integrate them with other services. Thus, this role includes a significant software engineering component.\n",
      "Offers a full-remote option\n",
      "We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\n",
      "____________\n",
      "GEMINI-2.5-PRO\n",
      "Heavily features agentic workflows (ie. langchain, tool use, prompt engineering, etc.)\n",
      "Implement generative AI workflows across the product, such as enabling users to describe their monitoring needs in natural language.\n",
      "Requires strong expertise in a topic/domain I am not familiar with\n",
      "General knowledge of the “modern data stack” ecosystem, especially data warehouses and databases.\n",
      "Requires a programming language I am not familiar with (and not Python)\n",
      "The web API is written in (modern) Java with Spring Boot 3, the web frontend is a VueJS application written in Typescript. You may occasionally need to make minor changes to this code base.\n",
      "The job is based in France and requires a good english level\n",
      "All written communication at Sifflet is in English, but the engineering team routinely uses French, so some level of fluency in French is required.\n",
      "Requires lots of experience in large scale training/inference/MLOps\n",
      "As we’re a small team, you will be expected to design, implement, deploy and maintain your projects in production, and integrate them with other services.\n",
      "Offers a full-remote option\n",
      "We have offices in Paris, but we’re very remote friendly - several team members are fully remote.\n"
     ]
    }
   ],
   "source": [
    "from numpy.char import upper\n",
    "\n",
    "\n",
    "for r in responses:\n",
    "    print(\"____________\")\n",
    "    print(r[\"model\"].upper())\n",
    "    for e in r[\"evaluation_grid\"]:\n",
    "        print(e[\"criteria\"])\n",
    "        print(e[\"evidence\"])\n",
    "    # print(e[\"criteria\"] for e in r[\"evaluation_grid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37309f3",
   "metadata": {},
   "source": [
    "# Evaluation sur Les exemples du jeu d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30623f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_tested = [(\"gpt-4.1\", True), (\"gpt-5-mini\", False), (\"gemini-2.5-flash\", False)]\n",
    "oracle_model = (\"gpt-5\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccae689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobseeker_agent.utils.paths import get_data_path\n",
    "evals_path = get_data_path() / \"reviewer\" / \"tests\" / \"5\" / \"evals.json\"\n",
    "with open(evals_path, \"r\") as f:\n",
    "    evals = json.load(f)\n",
    "\n",
    "ids = [4]\n",
    "# for ev in evals:\n",
    "#     ids.append(ev[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b23c79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 1\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740195.939168 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 2\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740330.323214 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 3\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740469.829023 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 4\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740598.169456 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 5\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740803.188805 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 6\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761740976.450089 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 7\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741094.993964 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 8\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741286.783700 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 9\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741438.654276 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 10\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741580.157041 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 11\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741720.866506 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 12\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741838.563378 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for job 13\n",
      "✅ Chargement du modèle OpenAI : gpt-5\n",
      "✅ Chargement du modèle OpenAI : gpt-4.1\n",
      "✅ Chargement du modèle OpenAI : gpt-5-mini\n",
      "✅ Chargement du modèle Gemini : gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761741990.196153 9513333 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[131]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_tested:\n\u001b[32m     18\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     result[model[\u001b[32m0\u001b[39m]] = \u001b[43mreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     end_time = time.time()\n\u001b[32m     21\u001b[39m     result[model[\u001b[32m0\u001b[39m]][\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m] = end_time - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mreview\u001b[39m\u001b[34m(model, job_description, job_title, company_name, location, with_correction)\u001b[39m\n\u001b[32m      6\u001b[39m llm = llm.with_structured_output(JobReviewResponse)\n\u001b[32m      7\u001b[39m message = HumanMessage(\n\u001b[32m      8\u001b[39m     content=review_prompt.format(job_description=job_description, profil_pro=profil_pro, job_title=job_title, company_name=company_name, location=location)\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_correction:\n\u001b[32m     12\u001b[39m     messages = [\n\u001b[32m     13\u001b[39m         message,\n\u001b[32m     14\u001b[39m         AIMessage(content=json.dumps(response)),\n\u001b[32m     15\u001b[39m         HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mPlease correct the evaluation grid. Evaluate each element. Is it correct ? Are there any missing element ? If elements are removed from the evaluation grid, don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt put them in the evaluation grid.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/runnables/base.py:3244\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3244\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3245\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3246\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/runnables/base.py:5711\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5705\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5706\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5709\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5710\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5711\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5712\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5713\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5714\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5715\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlocation is not supported\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc.message:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:869\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    868\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/grpc/_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:78\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     80\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/grpc/_channel.py:1192\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1185\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1190\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1191\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/grpc/_channel.py:1165\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1148\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1149\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1150\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1163\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1164\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1165\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1166\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "job_id = 3\n",
    "for id in ids:\n",
    "    print(f\"Evaluation for job {id}\")\n",
    "    result = {}\n",
    "    job = load_full_job(id)\n",
    "    job_description = job[\"description\"]\n",
    "    job_title = job[\"title\"]\n",
    "    company_name = job[\"company\"]\n",
    "    location = job[\"location\"]\n",
    "    start_time = time.time()\n",
    "    result[\"id\"] = id\n",
    "    result[\"job_description\"] = job_description\n",
    "    result[\"oracle\"] = review(oracle_model[0], job_description, job_title, company_name, location,  oracle_model[1])\n",
    "    end_time = time.time()\n",
    "    result[\"oracle\"][\"time\"] = end_time - start_time\n",
    "    for model in models_tested:\n",
    "        start_time = time.time()\n",
    "        result[model[0]] = review(model[0], job_description, job_title, company_name, location, model[1])\n",
    "        end_time = time.time()\n",
    "        result[model[0]][\"time\"] = end_time - start_time\n",
    "    results.append(result)\n",
    "\n",
    "# results\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c9693c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'job_description': 'Description not found.',\n",
       "  'oracle': {'evaluation_grid': [], 'score': 0, 'time': 26.32979917526245},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Vague description of actual tasks for a data scientist/engineer job',\n",
       "     'evidence': \"Job description is 'Description not found.' No details are provided about the actual tasks or requirements.\",\n",
       "     'score': -1},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': \"Job title and location: 'Research Scientist (AI) - Science Team', Paris, Île-de-France, France. The job title is in English, and the location is in France.\",\n",
       "     'score': 0.5}],\n",
       "   'score': -0.5,\n",
       "   'time': 5.39702296257019},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Vague description of actual tasks for a data scientist/engineer job',\n",
       "     'evidence': 'Description not found.',\n",
       "     'score': -1}],\n",
       "   'score': -1,\n",
       "   'time': 16.703629970550537},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [],\n",
       "   'score': 0,\n",
       "   'time': 10.142383098602295}},\n",
       " {'id': 2,\n",
       "  'job_description': \"AryaXAI stands at the forefront of AI innovation, revolutionizing AI for\\nmission-critical businesses by building explainable, safe, and aligned systems\\nthat scale responsibly. Our mission is to create AI tools that empower\\nresearchers, engineers, and organizations to unlock AI's full potential while\\nmaintaining transparency and safety.  \\n  \\nOur team thrives on a shared passion for cutting-edge innovation,\\ncollaboration, and a relentless drive for excellence. At AryaXAI, everyone\\ncontributes hands-on to our mission in a flat organizational structure that\\nvalues curiosity, initiative, and exceptional performance.  \\n  \\nAs a research scientist at AryaXAI, you will be uniquely positioned in our\\nteam to work on very large-scale industry problems and push forward the\\nfrontiers of AI technologies. You will become a part of the unique atmosphere\\nwhere startup culture meets research innovation, with key outcomes of speed\\nand reliability.  \\n  \\n**Responsibilities  \\n  \\n**\\n\\n  * You'll work on advanced problems related to AI explainability, AI safety, and AI alignment.\\n  * You'll have flexibility in picking up the specialization areas within ML/DL and problem types that address the above challenges.\\n  * Create new techniques around ML Observability & Alignment.\\n  * Collaborate with MLEs and SDE to roll out the features and manage their quality until they are fully stable.\\n  * Create and maintain technical and product documentation.\\n  * Publish papers in open forums like arxiv and present in industry forums like ICLR NeurIPS etc.   \\n  \\n\\n**Qualifications  \\n  \\n**\\n\\n  * Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.\\n  * Master or Ph.D in key engineering topics like computer science or Mathematics is required\\n  * Should have published peer-reviewed papers or contributed to opensource tools\\n  * Hands-on experience in working with deep learning frameworks like Tensorflow, Pytorch etc\\n  * Enjoys working on various DL problems that involve using different types of training data sets - textual, tabular, categorical, images etc\\n  * Comfortable deploying code in cloud environments/on-premise environments.\\n  * Good fundamentals in MLOps and productionising ML models.\\n  * Prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc.\\n  * 2+ years of hands-on experience in Deep Learning or Machine Learning.\\n  * Hands-on experience in implementing techniques like Transformer models, GANs, Deep Learning, etc.\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '\"Prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc.\"',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\" and the job description is written in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"Master or Ph.D in key engineering topics like computer science or Mathematics is required\"',\n",
       "     'score': 1.5}],\n",
       "   'score': 2,\n",
       "   'time': 89.27481865882874},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': \"Qualifications: 'Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.'\",\n",
       "     'score': 2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': \"Qualifications: 'Master or Ph.D in key engineering topics like computer science or Mathematics is required'\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': \"Job title: 'AI Research Scientist (Paris)', location: 'Paris, Île-de-France, France', description is in English.\",\n",
       "     'score': 0.5},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'The job requires prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc. Your profile does not mention hands-on experience with these specific explainability methods.',\n",
       "     'score': -2}],\n",
       "   'score': 2,\n",
       "   'time': 4.935046195983887},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (explicitly mentioned)',\n",
       "     'evidence': '\"Master or Ph.D in key engineering topics like computer science or Mathematics is required\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences (central to the role)\",\n",
       "     'evidence': '\"Prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc.\"',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and description is in English (job is in France and description provided in English)',\n",
       "     'evidence': '\"job title: AI Research Scientist (Paris), and location: Paris, Île-de-France, France\" (job description text is in English)',\n",
       "     'score': 0.5}],\n",
       "   'score': 2,\n",
       "   'time': 29.283622980117798},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': 'Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc.',\n",
       "     'score': -1.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'AI Research Scientist (Paris) and the job description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Master or Ph.D in key engineering topics like computer science or Mathematics is required',\n",
       "     'score': 1.5}],\n",
       "   'score': 3,\n",
       "   'time': 23.149363040924072}},\n",
       " {'id': 3,\n",
       "  'job_description': 'Develop the first useful quantum algorithms.  \\n  \\nHaiqu is building a world-leading software platform that enables previously\\nimpossible applications on modern quantum processors. Our full-stack approach\\nhas shown industry-first results in pilots with leading quantum early\\nadopters. Backed by top investors, we offer a unique opportunity to join a\\nfast-growing team to drive theoretical and practical quantum algorithm\\ndevelopment in the early FTQC (EFTQC) era.  \\n  \\nWe seek candidates with a solid academic background in theoretical and applied\\nquantum algorithms, a demonstrated capability for independent research, and a\\npassion for testing out theoretical concepts on real quantum hardware.  \\n  \\n**Responsibilities:  \\n  \\n** As a Research Scientist in Quantum Algorithms, you will explore and develop\\nnear-to-mid-term quantum applications on NISQ and EFTQC quantum architectures.\\nYou will run and design research projects on characterization, benchmarking,\\nand resource estimation for quantum algorithms, and conceptualize and\\nprototype proof-of-principle demonstrations. To this end, you will conduct\\nboth theoretical algorithm research and run practical experiments using state-\\nof-the-art quantum software and hardware.  \\n  \\n**Requirements  \\n  \\n**\\n\\n  * PhD in physics or related field (Computer Science, Mathematics)\\n  * A research background in quantum computing, quantum algorithms, quantum information theory, or computational physics with a demonstrated publication record\\n  * A good knowledge of quantum computing, including Error Correction, with a particular emphasis on recent research in quantum algorithms. Experience in resource estimation and practical optimization of quantum algorithms is a plus, as is good familiarity with quantum compilation and Tensor Network methods\\n  * Strong programming skills (preferably in Python) and a familiarity with at least one practical quantum computing framework (e.g. Qiskit)\\n  * Experience with ML frameworks (PyTorch, TensorFlow) is a plus\\n  * Excellent communication and presentation skills  \\n  \\n\\n**Benefits  \\n  \\n** We offer competitive compensation with significant equity and benefits.\\nJoin a diverse, flexible workplace building the future of quantum computing.\\n\\nShow more  Show less\\n\\n',\n",
       "  'oracle': {'evaluation_grid': [{'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms: (-4)\",\n",
       "     'evidence': '\"Experience in resource estimation and practical optimization of quantum algorithms is a plus.\"',\n",
       "     'score': -4},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences: (-2 if this domain/tool is central to the role)\",\n",
       "     'evidence': '\"A research background in quantum computing, quantum algorithms, quantum information theory, or computational physics with a demonstrated publication record\"',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified. : (+0.5)',\n",
       "     'evidence': 'Location: Paris, Île-de-France, France; job description is written in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD): (+1.5)',\n",
       "     'evidence': '\"PhD in physics or related field (Computer Science, Mathematics)\"',\n",
       "     'score': 1.5}],\n",
       "   'score': -4,\n",
       "   'time': 77.11481022834778},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '* PhD in physics or related field (Computer Science, Mathematics)',\n",
       "     'score': 1.5},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences (central to the role)\",\n",
       "     'evidence': 'We seek candidates with a solid academic background in theoretical and applied quantum algorithms... A research background in quantum computing, quantum algorithms, quantum information theory, or computational physics with a demonstrated publication record',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: Paris, Île-de-France, France. The job description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms\",\n",
       "     'evidence': 'Experience in resource estimation and practical optimization of quantum algorithms is a plus',\n",
       "     'score': -4}],\n",
       "   'score': -4,\n",
       "   'time': 6.3487629890441895},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"Experience in resource estimation and practical optimization of quantum algorithms is a plus, as is good familiarity with quantum compilation and Tensor Network methods\"',\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '\"Research background in quantum computing, quantum algorithms, quantum information theory...\" and \"familiarity with at least one practical quantum computing framework (e.g. Qiskit)\" (job title: Quantum Algrithms Researcher)',\n",
       "     'score': -2},\n",
       "    {'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms\",\n",
       "     'evidence': '\"run and design research projects on characterization, benchmarking, and resource estimation for quantum algorithms\" / \"practical optimization of quantum algorithms\"',\n",
       "     'score': -4},\n",
       "    {'criteria': 'The job is based in France and the description is in English',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\" and the job description text is written in English (e.g. \"Haiqu is building a world-leading software platform ...\")',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (explicitly mentioned)',\n",
       "     'evidence': '\"PhD in physics or related field (Computer Science, Mathematics)\"',\n",
       "     'score': 1.5}],\n",
       "   'score': -2,\n",
       "   'time': 31.813884258270264},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Develop the first useful quantum algorithms. / theoretical and practical quantum algorithm development / Research Scientist in Quantum Algorithms / research background in quantum computing, quantum algorithms, quantum information theory',\n",
       "     'score': -2.0},\n",
       "    {'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms\",\n",
       "     'evidence': 'Experience in resource estimation and practical optimization of quantum algorithms is a plus',\n",
       "     'score': -4.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'location: Paris, Île-de-France, France',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'PhD in physics or related field (Computer Science, Mathematics)',\n",
       "     'score': 1.5}],\n",
       "   'score': -4,\n",
       "   'time': 15.185747861862183}},\n",
       " {'id': 4,\n",
       "  'job_description': '**About Mistral  \\n  \\n** At Mistral AI, we believe in the power of AI to simplify tasks, save time,\\nand enhance learning and creativity. Our technology is designed to integrate\\nseamlessly into daily working life.  \\n  \\nWe democratize AI through high-performance, optimized, open-source and\\ncutting-edge models, products and solutions. Our comprehensive AI platform is\\ndesigned to meet enterprise as well as personal needs. Our offerings include\\nLe Chat, La Plateforme, Mistral Code and Mistral Compute - a suite that brings\\nfrontier intelligence to end-users.  \\n  \\nWe are a dynamic, collaborative team passionate about AI and its potential to\\ntransform society. Our diverse workforce thrives in competitive environments\\nand is committed to driving innovation. Our teams are distributed between\\nFrance, USA, UK, Germany and Singapore. We are creative, low-ego and team-\\nspirited.  \\n  \\nJoin us to be part of a pioneering company shaping the future of AI. Together,\\nwe can make a meaningful impact. See more about our culture on\\nhttps://mistral.ai/careers.  \\n  \\n_Mistral AI participates in the E-Verify program  \\n  \\n_ Role Summary  \\n  \\n**About The Research Engineering Team  \\n  \\n** The team spans **Platform** (shared infra & clean code) and\\n**Embedded**(inside research squads). Engineers can move along the\\nresearch↔production spectrum as needs or interests evolve.  \\n  \\nAs a Research Engineer – ML track, you’ll build and optimise the large-scale\\nlearning systems that power our open-weight models. Working hand-in-hand with\\nResearch Scientists, you’ll either join:  \\n  \\n\\n  * Platform RE Team: Enhance the shared training framework, data pipelines and cluster tooling used by every team; or\\n  * Embedded RE Team: Sit inside a research squad (Alignment, Pre-training, Multimodal, …) and turn fresh ideas into repeatable, scalable code  \\n  \\n  \\n\\n**Location:** Paris / London (hybrid) or remote from EU/UK  \\n  \\nWhat will you do  \\n  \\n\\n  * Accelerate researchers by taking on the heavy parts of large-scale ML pipelines and building robust tools\\n  * Interface cutting-edge research with production: integrate checkpoints, streamline evaluation, and expose APIs\\n  * Conduct experiments on the latest deep-learning techniques (sparsified 70 B + runs, distributed training on thousands of GPUs)\\n  * Design, implement and benchmark ML algorithms; write clear, efficient code in Python\\n  * Deliver prototypes that become production-grade components for Le Chat and our enterprise API  \\n  \\n  \\n\\n**About You  \\n  \\n**\\n\\n  * Master’s or PhD in Computer Science (or equivalent proven track record)\\n  * 4 + years working on large-scale ML codebases\\n  * Hands-on with PyTorch, JAX or TensorFlow; comfortable with distributed training (DeepSpeed / FSDP / SLURM / K8s)\\n  * Experience in deep learning, NLP or LLMs; bonus for CUDA or data-pipeline chops\\n  * Strong software-design instincts: testing, code review, CI/CD\\n  * Self-starter, low-ego, collaborative  \\n  \\n  \\n\\n**Benefits  \\n  \\n** France  \\n  \\n💰 Competitive cash salary and equity  \\n  \\n🥕 Food: Daily lunch vouchers  \\n  \\n🥎 Sport: Monthly contribution to a Gympass subscription  \\n  \\n🚴 Transportation: Monthly contribution to a mobility pass  \\n  \\n🧑\\u200d⚕️ Health: Full health insurance for you and your family  \\n  \\n🍼 Parental: Generous parental leave policy  \\n  \\n🌎 Visa sponsorship  \\n  \\nUK  \\n  \\n💰 Competitive cash salary and equity  \\n  \\n🚑 Insurance  \\n  \\n🚴 Transportation: Reimburse office parking charges, or £90 per month for\\npublic transport  \\n  \\n🥎 Sport: £90 per month reimbursement for gym membership  \\n  \\n🥕 Meal voucher: £200 monthly allowance for meals  \\n  \\n💰 Pension plan: SmartPension (percentages are 5% Employee & 3% Employer)  \\n  \\nWe may use artificial intelligence (AI) tools to support parts of the hiring\\nprocess, such as reviewing applications, analyzing resumes, or assessing\\nresponses. These tools assist our recruitment team but do not replace human\\njudgment. Final hiring decisions are ultimately made by humans. If you would\\nlike more information about how your data is processed, please contact us.\\n\\nShow more  Show less\\n\\n',\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "     'evidence': 'company name: Mistral AI',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Offers a full-remote option',\n",
       "     'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "     'score': 2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Description is in English; Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD)',\n",
       "     'evidence': 'Master’s or PhD in Computer Science (or equivalent proven track record)',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (beyond just \"good fundamentals\" or \"being comfortable\")',\n",
       "     'evidence': '4 + years working on large-scale ML codebases; Conduct experiments on the latest deep-learning techniques (sparsified 70 B + runs, distributed training on thousands of GPUs)',\n",
       "     'score': -1},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Hands-on with PyTorch, JAX or TensorFlow; comfortable with distributed training (DeepSpeed / FSDP / SLURM / K8s)',\n",
       "     'score': -2}],\n",
       "   'score': 3,\n",
       "   'time': 73.00970101356506},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': \"About You: Master's or PhD in Computer Science (or equivalent proven track record)\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company',\n",
       "     'evidence': 'Company name: Mistral AI (recognized as a top-tier AI company)',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Offers a full-remote option',\n",
       "     'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "     'score': 2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: Paris, Île-de-France, France; job description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Hands-on with PyTorch, JAX or TensorFlow; comfortable with distributed training (DeepSpeed / FSDP / SLURM / K8s). Your profile does not mention experience with JAX, DeepSpeed, FSDP, SLURM, or K8s, which are central to the role.',\n",
       "     'score': -2},\n",
       "    {'criteria': \"Requires 'deep expertise' / 'senior-level experience' / 'mastery' of MLOps, large-scale training, or inference optimization (beyond just 'good fundamentals' or 'being comfortable')\",\n",
       "     'evidence': '4+ years working on large-scale ML codebases; experience with distributed training on thousands of GPUs; strong software-design instincts: testing, code review, CI/CD.',\n",
       "     'score': -1}],\n",
       "   'score': 3,\n",
       "   'time': 4.868955135345459},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Top-tier company: Mistral AI',\n",
       "     'evidence': \"Company: Mistral AI (job header and 'About Mistral' section).\",\n",
       "     'score': 2},\n",
       "    {'criteria': 'PhD mentioned as acceptable/desired',\n",
       "     'evidence': '\"Master’s or PhD in Computer Science (or equivalent proven track record)\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Offers full-remote option',\n",
       "     'evidence': '\"Location: Paris / London (hybrid) or remote from EU/UK\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Job is based in France and the description is in English',\n",
       "     'evidence': 'Location includes Paris and the full job description is written in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires demonstrated expertise in specific tooling absent from profile (distributed-training stack)',\n",
       "     'evidence': '\"Hands-on with PyTorch, JAX or TensorFlow; comfortable with distributed training (DeepSpeed / FSDP / SLURM / K8s)\" — these specific tools (DeepSpeed, FSDP, SLURM, K8s) are not listed in your profile as hands-on experience.',\n",
       "     'score': -2}],\n",
       "   'score': 4,\n",
       "   'time': 34.40561294555664},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "     'evidence': 'you’ll build and optimise the large-scale learning systems that power our open-weight models. and Conduct experiments on the latest deep-learning techniques (sparsified 70 B + runs, distributed training on thousands of GPUs).',\n",
       "     'score': -3.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK and the entire job description being in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Master’s or PhD in Computer Science (or equivalent proven track record)',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "     'evidence': 'company name: Mistral AI',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Offers a full-remote option',\n",
       "     'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "     'score': 2.0}],\n",
       "   'score': 3,\n",
       "   'time': 46.47428297996521}},\n",
       " {'id': 5,\n",
       "  'job_description': \"As a research scientist on our team, you will partner with research engineers,\\nworking on fundamental research problems and collaborating with Datadog’s\\nProduct and Engineering teams to help translate research advances into\\ntangible benefits for our customers.  \\n  \\nBuilding on our proven track record of AI-powered solutions (e.g., Bits AI,\\nWatchdog, and Toto), Datadog AI Research is tackling high-risk, high-reward\\nprojects grounded in real-world challenges in cloud observability and\\nsecurity.  \\n  \\nWe are currently focused on three key research areas:  \\n  \\n\\n  * Observability Foundation Models – Building state-of-the-art models for advanced forecasting, anomaly detection, and multi-modal telemetry analysis (logs, metrics, traces, etc.). These models will also provide the foundation for our agents (described below) to natively analyze telemetry data. \\n  * Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge. \\n  * Production Code Repair Agents – Developing agents and models that leverage code, logs, runtime data, and other signals to identify, fix, and even preempt performance issues and security vulnerabilities in production code.   \\n  \\n\\n**What You’ll Do:  \\n  \\n**\\n\\n  * Conduct cutting-edge research in Generative AI and Machine Learning, aiming to build specialized Foundation Models and AI Agents for observability, site reliability engineering, and code repair\\n  * Leverage large-scale distributed training infrastructure to pre-train and post-train state-of-the-art models on diverse, real-world telemetry data\\n  * Build simulated environments to facilitate on-policy agentic training and evaluation.\\n  * Lead and contribute to research publications, present findings at top-tier conferences (e.g., NeurIPS, ICLR, ICML), and help open-source key model artifacts and benchmarks\\n  * Collaborate with cross-functional teams (e.g., Product, Engineering) to integrate advanced AI capabilities – like multi-modal analysis or automated incident resolution planning – into Datadog’s product ecosystem\\n  * Stay at the forefront of LLMs, Foundation Models, and Generative AI research and engage with the external research community\\n  * Foster a culture of scientific rigor, innovation, and practical impact, e.g., by actively participating in reading groups and mentoring interns  \\n  \\n\\n**Who You Are:  \\n  \\n**\\n\\n  * You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing (or have equivalent experience)\\n  * You possess extensive experience in designing and implementing deep learning models and agents, and have a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM) and ML libraries (PyTorch, TensorFlow)\\n  * You have a proven track record of conducting impactful research in the field with publications at top-tier venues (e.g., NeurIPS, ICLR, ICML, TMLR)\\n  * You're familiar with efficient training, post-training, fine-tuning, and inference techniques for large foundation models\\n  * You excel at explaining complex models and research findings to both technical and non-technical audiences\\n  * You have strong interest in open-science and open-source contributions, including establishing rigorous benchmarks and sharing research with the community  \\n  \\n\\n**Bonus Points (any of the following):  \\n  \\n**\\n\\n  * You have a demonstrated ability to bridge cutting-edge research and real-world product applications, ideally with an emphasis on large foundation models, generative AI agents, or domain-specific LLM deployments.\\n  * You’re passionate about pushing the boundaries of AI while maintaining a strong focus on customer impact, scalability, and responsible deployment of new technologies\\n  * You have experience writing production data pipelines and applications\\n  * You have hands-on experience with GPU programming and optimization, including experience in CUDA  \\n  \\n\\n _Datadog values people from all walks of life. We understand not everyone\\nwill meet all the above qualifications on day one. That's okay. If you’re\\npassionate about AI Research and want to grow your skills, we encourage you to\\napply.  \\n  \\n_**Benefits and Growth:  \\n  \\n**\\n\\n  * Competitive global benefits\\n  * New hire stock equity (RSUs) and employee stock purchase plan (ESPP)\\n  * Opportunity to collaborate closely with colleagues across the Datadog offices in New York City and Paris\\n  * Opportunity to attend and present at conferences and meetups\\n  * Intra-departmental mentor and buddy program for in-house networking\\n  * An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups)  \\n  \\n\\n_Benefits and Growth listed above may vary based on the country of your\\nemployment and the nature of your employment with Datadog.  \\n  \\n_**About Datadog:  \\n  \\n** Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare\\ncombination of growth and profitability. We are on a mission to break down\\nsilos and solve complexity in the cloud age by enabling digital\\ntransformation, cloud migration, and infrastructure monitoring of our\\ncustomers’ entire technology stacks. Built by engineers, for engineers,\\nDatadog is used by organizations of all sizes across a wide range of\\nindustries. Together, we champion professional development, diversity of\\nthought, innovation, and work excellence to empower continuous growth. Join\\nthe pack and become part of a collaborative, pragmatic, and thoughtful people-\\nfirst community where we solve tough problems, take smart risks, and celebrate\\none another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog\\nLearning Center.  \\n  \\n**Equal Opportunity at Datadog:  \\n  \\n** Datadog is proud to offer equal employment opportunity to everyone\\nregardless of race, color, ancestry, religion, sex, national origin, sexual\\norientation, age, citizenship, marital status, disability, gender identity,\\nveteran status, and other characteristics protected by law. We also consider\\nqualified applicants regardless of criminal histories, consistent with legal\\nrequirements. Here are our Candidate Legal Notices for your reference.  \\n  \\nDatadog endeavors to make our Careers Page accessible to all users. If you\\nwould like to contact us regarding the accessibility of our website or need\\nassistance completing the application process, please complete this form. This\\nform is for accommodation requests only and cannot be used to inquire about\\nthe status of applications.  \\n  \\n**Privacy and AI Guidelines:  \\n  \\n** Any information you submit to Datadog as part of your application will be\\nprocessed in accordance with Datadog’s Applicant and Candidate Privacy Notice.\\nFor information on our AI policy, please visit Interviewing at Datadog AI\\nGuidelines.\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"You hold a PhD ... with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Agentic workflows are part of the job (large part of the job is dedicated to this)',\n",
       "     'evidence': '\"Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents...\" and \"Build simulated environments to facilitate on-policy agentic training and evaluation.\" and \"Production Code Repair Agents – Developing agents and models...\"',\n",
       "     'score': 3},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '\"You possess extensive experience in designing and implementing deep learning models and agents, and have a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM) and ML libraries (PyTorch, TensorFlow)\"',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and requires a good English level (description in English + France-based)',\n",
       "     'evidence': 'Job description is written in English; Location: \"Paris, Île-de-France, France\"',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires deep expertise/senior-level experience in large-scale training',\n",
       "     'evidence': '\"Leverage large-scale distributed training infrastructure to pre-train and post-train state-of-the-art models...\" and \"have a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM)\"',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or equivalent experience)',\n",
       "     'evidence': '\"You hold a PhD in Computer Science, Machine Learning, or a related field... (or have equivalent experience)\"',\n",
       "     'score': 1.5}],\n",
       "   'score': 6,\n",
       "   'time': 99.96788811683655},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': \"'You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing (or have equivalent experience)'\",\n",
       "     'score': 2},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': \"The job mentions 'multi-step planning, reasoning, and domain-specific knowledge' as part of the SRE Autonomous Agents, but does not explicitly mention optimization, operations research, or combinatorial optimization. 'Planning' here refers to agentic planning, not mathematical optimization. This does not meet the criterion for explicit mention of algorithmic/mathematical optimization.\",\n",
       "     'score': 0},\n",
       "    {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "     'evidence': 'The job is focused on building AI agents (SRE Autonomous Agents, Production Code Repair Agents), which involves agentic workflows, but does not explicitly mention frameworks like langchain or prompt engineering. However, the core of the job is about agentic workflows in the sense of AI agents for automation and reasoning.',\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': \"The job requires 'a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM) and ML libraries (PyTorch, TensorFlow)'. Your profile lists PyTorch, but not distributed training frameworks like DeepSpeed or Megatron-LM. This is a secondary qualification, not central to the job title or primary responsibility.\",\n",
       "     'score': -1},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Job location: Paris, Île-de-France, France. Description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': \"'You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing (or have equivalent experience)'\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Datadog is a large, global SaaS company (NASDAQ: DDOG), with more than 150 employees.',\n",
       "     'score': -1}],\n",
       "   'score': 4,\n",
       "   'time': 13.541990041732788},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill (+2)',\n",
       "     'evidence': '\"Who You Are: ... deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Agentic workflows (tool-augmented agents, prompt/tool use) are part of the job (+2) + large part of the job (+1)',\n",
       "     'evidence': '\"SRE Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments\" and multiple references to \"agents\" as a key research area and product integration',\n",
       "     'score': 3},\n",
       "    {'criteria': 'Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile (central: distributed training frameworks e.g., DeepSpeed, Megatron-LM) (-2)',\n",
       "     'evidence': '\"You possess extensive experience ... and have a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM) and ML libraries (PyTorch, TensorFlow)\"',\n",
       "     'score': -2},\n",
       "    {'criteria': \"'Optimization' mentioned primarily for performance/inference (model training/inference efficiency) (-3)\",\n",
       "     'evidence': '\"You\\'re familiar with efficient training, post-training, fine-tuning, and inference techniques for large foundation models\" and \"Leverage large-scale distributed training infrastructure to pre-train and post-train state-of-the-art models\"',\n",
       "     'score': -3},\n",
       "    {'criteria': 'Job is based in France and description is in English (+0.5)',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\" and the full job description is written in English',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (penalty -1)',\n",
       "     'evidence': '\"Leverage large-scale distributed training infrastructure ...\" and \"extensive experience in designing and implementing deep learning models ... strong background in distributed training frameworks\" (language indicating senior/deep expertise)',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (explicitly mentioned) (+1.5)',\n",
       "     'evidence': '\"You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise ... (or have equivalent experience)\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company (Datadog) (+2)',\n",
       "     'evidence': '\"Datadog (NASDAQ: DDOG) is a global SaaS business...\" (well-known, large public tech company)',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Company has more than 150 employees (-1)',\n",
       "     'evidence': 'Datadog described as a global SaaS business (Datadog is a large public company with well over 150 employees)',\n",
       "     'score': -1}],\n",
       "   'score': 2.0,\n",
       "   'time': 43.57052493095398},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': 'You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing (or have equivalent experience)',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': 'Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge. and Collaborate with cross-functional teams (e.g., Product, Engineering) to integrate advanced AI capabilities – like multi-modal analysis or automated incident resolution planning – into Datadog’s product ecosystem',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "     'evidence': 'Observability Foundation Models – Building state-of-the-art models for advanced forecasting, anomaly detection, and multi-modal telemetry analysis (logs, metrics, traces, etc.). These models will also provide the foundation for our agents (described below) to natively analyze telemetry data., Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge., Production Code Repair Agents – Developing agents and models that leverage code, logs, runtime data, and other signals to identify, fix, and even preempt performance issues and security vulnerabilities in production code., Conduct cutting-edge research in Generative AI and Machine Learning, aiming to build specialized Foundation Models and AI Agents for observability, site reliability engineering, and code repair',\n",
       "     'score': 3.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'location: Paris, Île-de-France, France and the job description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (beyond just \"good fundamentals\" or \"being comfortable\")',\n",
       "     'evidence': 'You possess extensive experience in designing and implementing deep learning models and agents, and have a strong background in distributed training frameworks (e.g., DeepSpeed, Megatron-LM) and ML libraries (PyTorch, TensorFlow)',\n",
       "     'score': -1.0},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'You hold a PhD in Computer Science, Machine Learning, or a related field, with deep expertise in areas like generative modeling, AI agents, reinforcement learning, or natural language processing (or have equivalent experience)',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company',\n",
       "     'evidence': 'Based on prior knowledge of Datadog as a leading SaaS company in cloud observability and security with significant AI investment.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Datadog (NASDAQ: DDOG) is a global SaaS business...',\n",
       "     'score': -1.0}],\n",
       "   'score': 9,\n",
       "   'time': 30.360820055007935}},\n",
       " {'id': 6,\n",
       "  'job_description': \"Au sein du Département _Corporate Research & Science_, vous intégrerez\\nl’équipe _AI for Manufacturing_ _World Twin_ qui s’intéresse à des\\nproblématiques liées à l’Intelligence Artificielle dans des environnements\\nindustriels mixant le réel et le virtuel, à l’image des jumeaux virtuels.  \\n  \\nQuand la donnée est rare et confidentielle, les univers virtuels peuvent être\\nun atout majeur pour la modélisation mathématique et l’apprentissage\\nstatistique afin de capitaliser et automatiser le savoir-faire industriel.  \\n  \\nSi les techniques d’apprentissage statistique ont prouvé leur efficacité sur\\ndes données réelles collectées par des capteurs physiques (caméras, appareils\\nphoto, etc.), leur déploiement dans des environnements 3D mixant le réel et le\\nvirtuel, reste un défi majeur. Ce domaine soulève encore de nombreuses\\nquestions, en particulier en ce qui concerne la robustesse, la capacité de\\ngénéralisation et l’adaptation aux contraintes industrielles. En nous appuyant\\nsur les avancées des _Vision-Language Models_ et sur de nouveaux paradigmes\\nd’apprentissages, nous cherchons à concevoir des solutions innovantes,\\ncapables de s’adapter à des contextes industriels variés et en constante\\névolution.  \\n  \\n**Vos missions:  \\n  \\n**\\n\\n  * Réaliser des études et référentiels sur des technologies clés autour des jumeaux virtuels et différents paradigmes d’apprentissages au service de l’industrie.\\n  * Développer des prototypes et des composants technologiques innovants.\\n  * Démontrer l’applicabilité et l’usage des composants dans des scénarii adaptés aux besoins de la R&D.\\n  * Au travers des études et prototypes réalisés, il/elle élaborera des recommandations technologiques et il/elle accompagnera leur transfert vers les équipes de développement produit.\\n  * Participation à l’écriture de brevets dans le cadre de ses travaux.  \\n  \\n\\n**Vos qualifications :  \\n  \\n**\\n\\n  * Doctorat (PhD) en Machine Learning / mathématique appliquée ou formation d’ingénieur ou universitaire (de type Bac+5) avec une majeure en Machine Learning / Data Science, vous avez minimum 4 ans d'expériene.\\n  * Vous disposez de solides connaissances en mathématiques appliquées, algorithmique, modélisation 3D et apprentissage statistique.\\n  * Vous disposez de compétences en programmation en python et C++, Frameworks de Deep Learning (e.g. Tensorflow, Pytorch) et en rédaction de document et de présentation.\\n  * Une expérience professionnelle avec les Vision Language Models et/ou le Reinforcement Learning est un véritable plus.\\n  * Vous avez un bon niveau d’anglais\\n  * Outre les compétences techniques, vous êtes doté(e) d’un esprit d’analyse et de synthèse, d’une bonne aptitude à la restitution d’information et à la communication.  \\n  \\n\\nInclusion statement  \\n  \\nAs a game-changer in sustainable technology and innovation, Dassault Systèmes\\nis striving to build more inclusive and diverse teams across the globe. We\\nbelieve that our people are our number one asset and we want all employees to\\nfeel empowered to bring their whole selves to work every day. It is our goal\\nthat our people feel a sense of pride and a passion for belonging. As a\\ncompany leading change, it’s our responsibility to foster opportunities for\\nall people to participate in a harmonized Workforce of the Future.\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"Une expérience professionnelle avec les Vision Language Models et/ou le Reinforcement Learning est un véritable plus.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '\"Vous disposez de compétences en programmation en python et C++\" (C++ non listé comme compétence dans mon profil récent)',\n",
       "     'score': -2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '\"Vous disposez de solides connaissances en ... modélisation 3D\" (modélisation 3D absente de mon profil)',\n",
       "     'score': -2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"Doctorat (PhD) en Machine Learning / mathématique appliquée ou formation d’ingénieur ...\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Dassault Systèmes est une multinationale bien établie (connaissance a priori: >20 000 employés)',\n",
       "     'score': -1}],\n",
       "   'score': -1.5,\n",
       "   'time': 98.47651195526123},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"Une expérience professionnelle avec les Vision Language Models et/ou le Reinforcement Learning est un véritable plus.\" RL is not a key requirement, but is explicitly mentioned as a plus. According to the criteria, this still counts as +2.',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"solides connaissances en mathématiques appliquées, algorithmique, modélisation 3D et apprentissage statistique.\" This covers mathematical and algorithmic skills, but does not explicitly mention optimization or operations research. The mention of \\'algorithmique\\' and \\'mathématiques appliquées\\' is close, but not explicit. According to the criteria, explicit mention is required. Therefore, this should NOT be included.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': '\"Vous avez un bon niveau d’anglais\" and location is \"Vélizy-Villacoublay, Île-de-France, France\".',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"Doctorat (PhD) en Machine Learning / mathématique appliquée ou formation d’ingénieur ou universitaire (de type Bac+5) avec une majeure en Machine Learning / Data Science, vous avez minimum 4 ans d\\'expériene.\" PhD is explicitly mentioned as a possible requirement.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Dassault Systèmes is a large multinational company with thousands of employees.',\n",
       "     'score': -1}],\n",
       "   'score': 3,\n",
       "   'time': 10.802553176879883},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '\"Une expérience professionnelle avec les Vision Language Models et/ou le Reinforcement Learning est un véritable plus.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"Vous disposez de solides connaissances en mathématiques appliquées, algorithmique, modélisation 3D et apprentissage statistique.\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"Doctorat (PhD) en Machine Learning / mathématique appliquée ou formation d’ingénieur ou universitaire (de type Bac+5) avec une majeure en Machine Learning / Data Science, vous avez minimum 4 ans d\\'expériene.\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': '\"company name: Dassault Systèmes\" (Dassault Systèmes is a large established company with well over 150 employees)',\n",
       "     'score': -1}],\n",
       "   'score': 4.5,\n",
       "   'time': 32.66773009300232},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': 'Une expérience professionnelle avec les Vision Language Models et/ou le Reinforcement Learning est un véritable plus.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': 'solides connaissances en mathématiques appliquées, algorithmique, modélisation 3D et apprentissage statistique.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Vélizy-Villacoublay, Île-de-France, France and Vous avez un bon niveau d’anglais',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Doctorat (PhD) en Machine Learning / mathématique appliquée ou formation d’ingénieur ou universitaire (de type Bac+5) avec une majeure en Machine Learning / Data Science',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Dassault Systèmes is a large company with more than 150 employees.',\n",
       "     'score': -1.0}],\n",
       "   'score': 5,\n",
       "   'time': 24.28971290588379}},\n",
       " {'id': 7,\n",
       "  'job_description': '**Job Description  \\n  \\n** The Road Safety AI team is seeking a motivated candidate, with a solid\\nbackground in Software Development and AI for Computer Vision, to work on the\\ndevelopment and improvement of algorithms to efficiently address Road Safety\\nbusiness or customer needs.  \\n  \\nOur studies cover all aspects of scientific research, from exploration of the\\nState of The Art (SOTA), data collection cleaning and annotation, algorithms\\ndesign and implementation, to the publication of research papers or patents.\\nNot just that, our algorithms are deployed in IDEMIA road safety equipment\\nused to detect traffic law violations and contribute to making Vision Zero\\nreality.  \\n  \\nSome of the studies we work on: vehicle segmentation and tracking, monocular\\n3D vision, phone usage and seatbelt violations’ detection, etc.  \\n  \\n**Key Missions  \\n  \\n**\\n\\n  * Designs, implements, improves and optimizes statistically robust, efficient, secure and scalable algorithms while respecting platforms’ constraints\\n  * Develops test strategies and methodologies to evaluate new or competing algorithms\\n  * Presents algorithms and results for internal community challenges\\n  * Stays up to date on latest state-of-the-art research and algorithm development methodologies\\n  * Provides support to solution design, implementation, customization and operations\\n  * Closes proactively the loop with operational data/logs to ensure the algorithms are fully effective in operations\\n  * Coaches less experienced researchers (depending on seniority)  \\n  \\n\\n**Profile Description  \\n  \\n**\\n\\n  * Graduate from an engineering school or holder of a Master’s degree (M2) in Artificial Intelligence, Computer Vision, or a related field\\n  * PhD in Computer Vision or AI is a plus\\n  * 1 to 5 years of experience in a similar role in R&D or product development\\n  * Strong understanding of Deep Learning and Computer Vision fundamentals\\n  * Proven involvement in at least three personal or professional projects in Computer Vision or Natural Language Processing (NLP)\\n  * Experience in Object Detection and Tracking is a plus\\n  * Proficient in Python and the PyTorch framework\\n  * Strong background in software development and data analysis\\n  * Fluent in English (able to read scientific papers and present technical work)\\n  * Proficient in French (written and spoken)\\n  * Curious, proactive, and autonomous\\n  * Results-driven with good teamwork and knowledge-sharing skills\\n\\nShow more  Show less\\n\\n',\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'The job is based in France and requires a good English level',\n",
       "     'evidence': 'Location: Courbevoie, Île-de-France, France; \"Fluent in English (able to read scientific papers and present technical work)\"',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or is a plus)',\n",
       "     'evidence': '\"PhD in Computer Vision or AI is a plus\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Company: IDEMIA (large multinational; >150 employees)',\n",
       "     'score': -1}],\n",
       "   'score': 1,\n",
       "   'time': 46.229532957077026},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': \"The job description mentions 'optimizes statistically robust, efficient, secure and scalable algorithms', but this refers to algorithmic efficiency and robustness, not mathematical/operations research optimization. There is no explicit mention of mathematical optimization, operations research, or combinatorial optimization. This criterion is NOT met.\",\n",
       "     'score': 0},\n",
       "    {'criteria': 'Requires a programming language I am not familiar with, AND does not mention Python',\n",
       "     'evidence': 'The job explicitly requires Python and PyTorch, both of which you are familiar with. This criterion is NOT met (no penalty or bonus).',\n",
       "     'score': 0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'The job is located in Courbevoie, Île-de-France, France, the description is in English, and it requires fluency in both English and French.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': \"The job description states: 'PhD in Computer Vision or AI is a plus.'\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'IDEMIA is a large company with more than 150 employees.',\n",
       "     'score': -1}],\n",
       "   'score': 1,\n",
       "   'time': 16.286128044128418},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Requires a PhD in a related field (explicitly mentioned as a plus) (+1.5)',\n",
       "     'evidence': '\"PhD in Computer Vision or AI is a plus\" (Profile Description)',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'The job is based in France and requires a good English level (+0.5)',\n",
       "     'evidence': 'Location: \"Courbevoie, Île-de-France, France\" (job location) and \"Fluent in English (able to read scientific papers and present technical work)\" (Profile Description)',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Company appears to be a large established firm (more than 150 employees) (-1)',\n",
       "     'evidence': 'Company name: \"IDEMIA\" (company listed for the job)',\n",
       "     'score': -1}],\n",
       "   'score': 1.0,\n",
       "   'time': 30.74977397918701},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'location: Courbevoie, Île-de-France, France and Fluent in English (able to read scientific papers and present technical work)',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'PhD in Computer Vision or AI is a plus',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'IDEMIA is a large multinational company.',\n",
       "     'score': -1.0}],\n",
       "   'score': 1,\n",
       "   'time': 30.37668776512146}},\n",
       " {'id': 8,\n",
       "  'job_description': \"As a research engineer on our team, you will partner with research scientists\\nto turn research ideas into working systems; building the data, tooling, and\\ninfrastructure that enable rapid iteration, trustworthy evaluation, and a\\nsmooth path from prototype to production.  \\n  \\nBuilding on our proven track record of AI-powered solutions (e.g., Bits AI,\\nWatchdog, and Toto), Datadog AI Research is tackling high-risk, high-reward\\nprojects grounded in real-world challenges in cloud observability and\\nsecurity.  \\n  \\nWe are currently focused on three key research areas:  \\n  \\n\\n  * Observability Foundation Models – Building state-of-the-art models for advanced forecasting, anomaly detection, and multi-modal telemetry analysis (logs, metrics, traces, etc.). These models will also provide the foundation for our agents (described below) to natively analyze telemetry data. \\n  * Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge. \\n  * Production Code Repair Agents – Developing agents and models that leverage code, logs, runtime data, and other signals to identify, fix, and even preempt performance issues and security vulnerabilities in production code.   \\n  \\n\\n**What You’ll Do:  \\n  \\n**\\n\\n  * Build and operate datasets, training and evaluation pipelines, benchmarks, and internal tooling \\n  * Implement models, run experiments at scale, and profile for reliability, performance, and cost \\n  * Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery \\n  * Make the research stack observable, reproducible, and easier to use \\n  * Establish rigorous automated benchmarks and regression tests for forecasting, anomaly detection, multi-modal analysis, agents, and code repair tasks \\n  * Collaborate with Research Scientists, Product, and Engineering to integrate advanced AI capabilities into Datadog’s product ecosystem and to harden prototypes into reliable services \\n  * Contribute high-quality code, documentation, and open-source artifacts that enable the community and internal teams to reproduce, extend, and evaluate results   \\n  \\n\\n**Who You Are:  \\n  \\n**\\n\\n  * You have strong software engineering skills with experience in domains such as observability, SRE, or security \\n  * You have depth in distributed computing and ML systems for training and inference at scale; experience with Ray, Slurm, or similar frameworks is a plus \\n  * You are proficient in Python, familiar with a systems language (e.g., Rust, C++, or Go), and you are comfortable with modern cloud and data infrastructure \\n  * You have practical experience implementing and operating ML training and inference systems (e.g., PyTorch or JAX), including containerization, orchestration, and GPU acceleration \\n  * You are familiar with efficient training, fine-tuning, and inference techniques for large foundation models \\n  * You can explain design and performance trade-offs clearly to both technical and non-technical audiences \\n  * You have a strong interest in open-science and open-source contributions, including establishing rigorous benchmarks and sharing artifacts with the community   \\n  \\n\\n**Bonus Points:  \\n  \\n**\\n\\n  * You have a demonstrated ability to bridge cutting-edge research prototypes and real-world product applications, ideally with large foundation models, generative AI agents, or domain-specific LLM deployments \\n  * You are passionate about pushing the boundaries of AI while maintaining a strong focus on customer impact, scalability, and responsible deployment of new technologies \\n  * You have hands-on experience with GPU programming and optimization, including experience in CUDA \\n  * You have experience writing production data pipelines and applications \\n  * You have experience supporting or contributing to research publications   \\n  \\n\\n_Datadog values people from all walks of life. We understand not everyone will\\nmeet all the above qualifications on day one. That's okay. If you’re\\npassionate about AI Research and want to grow your skills, we encourage you to\\napply.  \\n  \\n_**Benefits and Growth:  \\n  \\n**\\n\\n  * Competitive global benefits \\n  * New hire stock equity (RSUs) and employee stock purchase plan (ESPP) \\n  * Opportunity to collaborate closely with colleagues across the Datadog offices in New York City and Paris \\n  * Opportunity to attend and present at conferences and meetups \\n  * Intra-departmental mentor and buddy program for in-house networking \\n  * An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups)   \\n  \\n\\n_Benefits and Growth listed above may vary based on the country of your\\nemployment and the nature of your employment with Datadog.  \\n  \\n_**About Datadog:  \\n  \\n** Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare\\ncombination of growth and profitability. We are on a mission to break down\\nsilos and solve complexity in the cloud age by enabling digital\\ntransformation, cloud migration, and infrastructure monitoring of our\\ncustomers’ entire technology stacks. Built by engineers, for engineers,\\nDatadog is used by organizations of all sizes across a wide range of\\nindustries. Together, we champion professional development, diversity of\\nthought, innovation, and work excellence to empower continuous growth. Join\\nthe pack and become part of a collaborative, pragmatic, and thoughtful people-\\nfirst community where we solve tough problems, take smart risks, and celebrate\\none another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog\\nLearning Center.  \\n  \\n**Equal Opportunity at Datadog:  \\n  \\n** Datadog is proud to offer equal employment opportunity to everyone\\nregardless of race, color, ancestry, religion, sex, national origin, sexual\\norientation, age, citizenship, marital status, disability, gender identity,\\nveteran status, and other characteristics protected by law. We also consider\\nqualified applicants regardless of criminal histories, consistent with legal\\nrequirements. Here are our Candidate Legal Notices for your reference.  \\n  \\nDatadog endeavors to make our Careers Page accessible to all users. If you\\nwould like to contact us regarding the accessibility of our website or need\\nassistance completing the application process, please complete this form. This\\nform is for accommodation requests only and cannot be used to inquire about\\nthe status of applications.  \\n  \\n**Privacy and AI Guidelines:  \\n  \\n** Any information you submit to Datadog as part of your application will be\\nprocessed in accordance with Datadog’s Applicant and Candidate Privacy Notice.\\nFor information on our AI policy, please visit Interviewing at Datadog AI\\nGuidelines.\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': '“Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery”',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Agentic workflows are part of the job, and a large part is dedicated to this',\n",
       "     'evidence': 'Research areas include “Site Reliability Engineering (SRE) Autonomous Agents” and “Production Code Repair Agents”; plus “Establish rigorous automated benchmarks and regression tests for … agents, and code repair tasks.”',\n",
       "     'score': 3},\n",
       "    {'criteria': 'Requires demonstrated expertise in a specific technical domain or toolset absent from my profile',\n",
       "     'evidence': '“Orchestrate distributed training and distributed RL with Ray …” and “experience with Ray, Slurm, or similar frameworks is a plus.”',\n",
       "     'score': -2},\n",
       "    {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms',\n",
       "     'evidence': '“Build and operate datasets, training and evaluation pipelines, benchmarks, and internal tooling”; “Make the research stack observable, reproducible, and easier to use”; “Implement models, run experiments at scale, and profile for reliability, performance, and cost.”',\n",
       "     'score': -3},\n",
       "    {'criteria': 'The job is based in France and the description is in English',\n",
       "     'evidence': 'Location: Paris, Île-de-France, France; job description is written in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires deep expertise in large-scale ML systems/training/inference',\n",
       "     'evidence': '“You have depth in distributed computing and ML systems for training and inference at scale”',\n",
       "     'score': -1},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Datadog is a public company: “Datadog (NASDAQ: DDOG) is a global SaaS business,” indicating a large organization well above 150 employees.',\n",
       "     'score': -1}],\n",
       "   'score': -1.5,\n",
       "   'time': 107.80760669708252},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': \"The job description states: 'Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery.'\",\n",
       "     'score': 2},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': 'The job description does not mention algorithmic/mathematical optimization, operations research, or related terms.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "     'evidence': \"The job description includes: 'Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments...' and 'Production Code Repair Agents – Developing agents and models...' This is about building AI agents, but does not mention agentic workflow frameworks (langchain, tool use, prompt engineering) explicitly. However, the focus on agents is strong, so +2 is justified.\",\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'The job requires proficiency in Python and familiarity with a systems language (e.g., Rust, C++, or Go). The profile mentions some exposure to C++ and Java, but not Rust or Go. However, Python is the main language, and the systems language is not central. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Requires a programming language I am not familiar with, AND does not mention Python',\n",
       "     'evidence': 'The job requires Python as the main language, which is present in the profile. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms',\n",
       "     'evidence': 'The job description balances infrastructure (datasets, pipelines, distributed training) and algorithms (model implementation, research, agents). Not more focused on infrastructure than algorithms. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Vague description of actual tasks for a data scientist/engineer job',\n",
       "     'evidence': 'The job description is detailed and specific about tasks and responsibilities. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "     'evidence': 'Optimization is mentioned in the context of reliability, performance, and cost, but not as the primary focus. The main focus is on research and building agents/models. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: Paris, Île-de-France, France. The job description is in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'More managerial than technical role',\n",
       "     'evidence': 'The role is technical, not managerial. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Involves leading a team of highly qualified/experienced people (junior excluded)',\n",
       "     'evidence': 'No mention of team leadership responsibilities. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Involves coaching world-class scientists',\n",
       "     'evidence': 'No mention of coaching world-class scientists. No penalty.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "     'evidence': 'Datadog is not considered a top-tier AI research company by the provided definition.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Datadog is a global SaaS business, publicly traded (NASDAQ: DDOG), and has more than 150 employees.',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Offers a full-remote option',\n",
       "     'evidence': 'No mention of a full-remote option in the job description.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Consulting job for a standard/low-tier consulting firm',\n",
       "     'evidence': 'Not a consulting job.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'In the defense sector',\n",
       "     'evidence': 'Not in the defense sector.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'In the robotics sector',\n",
       "     'evidence': 'Not in the robotics sector.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'If not french, requires security clearance',\n",
       "     'evidence': 'No mention of security clearance.',\n",
       "     'score': 0},\n",
       "    {'criteria': \"Requires 'deep expertise' / 'senior-level experience' / 'mastery' of MLOps, large-scale training, or inference optimization (beyond just 'good fundamentals' or 'being comfortable')\",\n",
       "     'evidence': \"The job requires 'depth in distributed computing and ML systems for training and inference at scale', but does not use terms like 'deep expertise', 'senior-level', or 'mastery'. No penalty.\",\n",
       "     'score': 0},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'The job description does not explicitly mention a PhD as a requirement or a plus.',\n",
       "     'score': 0}],\n",
       "   'score': 3.5,\n",
       "   'time': 13.84049916267395},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill (+2)',\n",
       "     'evidence': '\"Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Agentic workflows / agents are part of the job (+2), and a large part of the job is dedicated to this (+1)',\n",
       "     'evidence': '\"Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents...\"; \"Production Code Repair Agents – Developing agents and models...\"; \"These models will also provide the foundation for our agents...\"',\n",
       "     'score': 3},\n",
       "    {'criteria': 'Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile (central to the role) (-2)',\n",
       "     'evidence': '\"Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery\"  (no Ray/Slurm experience listed in the provided profile)',\n",
       "     'score': -2},\n",
       "    {'criteria': 'The job is based in France and the description is in English (+0.5)',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\"; full job description written in English',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires \"depth\" / senior-level experience in distributed ML systems / large-scale training or inference (penalty -1)',\n",
       "     'evidence': '\"You have depth in distributed computing and ML systems for training and inference at scale; experience with Ray, Slurm, or similar frameworks is a plus\"; \"You are proficient in Python... comfortable with modern cloud and data infrastructure\"',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Top-tier company (prior knowledge) (+2)',\n",
       "     'evidence': '\"Datadog (NASDAQ: DDOG) is a global SaaS business\" (Datadog is a well-known, large, publicly-traded tech company)',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Company larger than 150 employees (penalty -1)',\n",
       "     'evidence': '\"Datadog (NASDAQ: DDOG) is a global SaaS business... Datadog is used by organizations of all sizes across a wide range of industries.\" (implies a large, established company)',\n",
       "     'score': -1}],\n",
       "   'score': 3.5,\n",
       "   'time': 38.45830798149109},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': 'Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': 'Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "     'evidence': 'Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge. ; Production Code Repair Agents – Developing agents and models that leverage code, logs, runtime data, and other signals to identify, fix, and even preempt performance issues and security vulnerabilities in production code. ; Observability Foundation Models – These models will also provide the foundation for our agents (described below) to natively analyze telemetry data.',\n",
       "     'score': 3.0},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'You have strong software engineering skills with experience in domains such as observability, SRE, or security',\n",
       "     'score': -2.0},\n",
       "    {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms',\n",
       "     'evidence': 'Build and operate datasets, training and evaluation pipelines, benchmarks, and internal tooling ; Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery ; Make the research stack observable, reproducible, and easier to use ; comfortable with modern cloud and data infrastructure ; practical experience implementing and operating ML training and inference systems (e.g., PyTorch or JAX), including containerization, orchestration, and GPU acceleration',\n",
       "     'score': -3.0},\n",
       "    {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "     'evidence': 'Implement models, run experiments at scale, and profile for reliability, performance, and cost ; GPU programming and optimization, including experience in CUDA',\n",
       "     'score': -3.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'job title: AI Research Engineer - Datadog AI Research (DAIR), and location: Paris, Île-de-France, France',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (beyond just \"good fundamentals\" or \"being comfortable\")',\n",
       "     'evidence': 'You have depth in distributed computing and ML systems for training and inference at scale ; You have practical experience implementing and operating ML training and inference systems (e.g., PyTorch or JAX), including containerization, orchestration, and GPU acceleration ; You are familiar with efficient training, fine-tuning, and inference techniques for large foundation models',\n",
       "     'score': -1.0},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare combination of growth and profitability.',\n",
       "     'score': -1.0}],\n",
       "   'score': -2.5,\n",
       "   'time': 38.28434896469116}},\n",
       " {'id': 9,\n",
       "  'job_description': \"**Job Description  \\n  \\n****Purpose  \\n  \\n** The Road Safety AI team is seeking a motivated candidate, with a solid\\nbackground in Software Development and AI for Computer Vision, to work on the\\ndevelopment and improvement of algorithms to efficiently address Road Safety\\nbusiness or customer needs.  \\n  \\nOur studies cover all aspects of scientific research, from exploration of the\\nState of The Art (SOTA), data collection cleaning and annotation, algorithms\\ndesign and implementation, to the publication of research papers or patents.\\nNot just that, our algorithms are deployed in IDEMIA road safety equipment\\nused to detect traffic law violations and contribute to making Vision Zero\\nreality.  \\n  \\nSome of the studies we work on: vehicle segmentation and tracking, monocular\\n3D vision, phone usage and seatbelt violations’ detection, etc.  \\n  \\n**Key Missions  \\n  \\n**\\n\\n  * Designs, implements, improves and optimizes statistically robust, efficient, secure and scalable algorithms while respecting platforms’ constraints\\n  * Develops test strategies and methodologies to evaluate new or competing algorithms\\n  * Presents algorithms and results for internal community challenges\\n  * Stays up to date on latest state-of-the-art research and algorithm development methodologies\\n  * Provides support to solution design, implementation, customization and operations\\n  * Closes proactively the loop with operational data/logs to ensure the algorithms are fully effective in operations\\n  * Coaches less experienced researchers (depending on seniority)  \\n  \\n\\n**Profile Description  \\n  \\n****Education** : Engineering School or a Master's (M2) graduate who checks\\nthe following requirements (technical and soft skills). PhD in Computer Vision\\nor AI is a plus.  \\n  \\n**Required Technical Skills**  \\n  \\n\\n  * Strong knowledge of Deep Learning and Computer Vision.\\n    * At least three [personal or professional] projects/experiences in the field of Computer Vision or NLP.\\n    * Experience in Object Detection and Tracking is a plus.\\n  * Proficiency in Python and PyTorch.\\n  * Solid training in data analysis and software development.  \\n\\n**Soft Skills & Languages  \\n  \\n**\\n\\n  * Proficient in English (e.g. reading scientific articles, presenting work)\\n  * Proficient in French\\n  * Curious, proactive, and autonomous\\n  * Results-oriented  \\n  \\n\\n**Seniority level:** A first experience (1-5 years) in a similar position is a\\nplus.\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'The job is based in France and requires a good English level',\n",
       "     'evidence': 'Location: Osny, Île-de-France, France; and \"Proficient in English (e.g. reading scientific articles, presenting work)\" (description in English)',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"PhD in Computer Vision or AI is a plus.\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'IDEMIA is a large multinational with >15,000 employees (public information).',\n",
       "     'score': -1}],\n",
       "   'score': 1,\n",
       "   'time': 53.70189118385315},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'The job requires at least three [personal or professional] projects/experiences in Computer Vision or NLP. Your profile lists one significant personal project in Computer Vision, but not three distinct projects/experiences. However, you do have a strong ML/AI background and a PhD.',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'PhD in Computer Vision or AI is a plus. You have a PhD in a closely related field (AI, RL, optimization).',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Job is located in Osny, Île-de-France, France. The description is in English and requires proficiency in English and French.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'IDEMIA is a large company with more than 150 employees.',\n",
       "     'score': -1}],\n",
       "   'score': 0,\n",
       "   'time': 8.974778890609741},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Requires a PhD in a field close to mine (or mentioned as a plus): +1.5',\n",
       "     'evidence': '\"PhD in Computer Vision or AI is a plus.\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Job is based in France and the description/requirements request good English: +0.5',\n",
       "     'evidence': 'Location: Osny, Île-de-France, France; and \"Proficient in English (e.g. reading scientific articles, presenting work)\"',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'More than 150 employees (company is a large multinational): -1',\n",
       "     'evidence': 'company name: IDEMIA (IDEMIA is a large multinational company, known to have >150 employees)',\n",
       "     'score': -1}],\n",
       "   'score': 1.0,\n",
       "   'time': 49.71536207199097},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Osny, Île-de-France, France, Proficient in English (e.g. reading scientific articles, presenting work)',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'PhD in Computer Vision or AI is a plus.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'IDEMIA is a large company with more than 150 employees (prior knowledge).',\n",
       "     'score': -1.0}],\n",
       "   'score': 1,\n",
       "   'time': 27.948697805404663}},\n",
       " {'id': 10,\n",
       "  'job_description': \"**Hexaly is a fast-growing software company in Mathematical Optimization** ,\\nalso known as Operations Research or Decision Science. The team develops\\nHexaly Optimizer, the fastest solver for Routing, Scheduling, Packing, and\\nmore, and Hexaly Studio, an innovative low-code platform to build optimization\\napplications in days. In addition, Hexaly delivers turnkey optimization\\napplications through its professional services. In solid growth and\\nprofitability (+32% in 2022, +23% in 2023, +24% in 2024), the company counts\\namong its customers the most prominent companies worldwide, like Amazon,\\nFedEx, Starbucks, Airbus, Bosch, Sony, Renault, Kirin, Shell, TotalEnergies,\\nRepsol, Publicis, JCDecaux, Softbank, and many others.\\n\\n  \\n\\n**_We currently have 5 Senior Operations Research Scientist positions open at\\nHexaly._**\\n\\n  \\n\\n**Your job**\\n\\n  \\n\\nYou are part of the Hexaly tech team. Daily:\\n\\n  * You develop new features, algorithm improvements, and fix bugs in Hexaly Optimizer.\\n  * You provide Hexaly users with dedicated support and training.\\n  * You participate in Hexaly professional services, such as developing turnkey applications for clients.\\n\\n  \\n\\n**Your profile**\\n\\n  \\n\\n  * **You have at least 5 years of experience in Mathematical Optimization, preferably in business and industry.**\\n  * You have a Ph.D. or a Master's in Operations Research, Computer Science, or Applied Mathematics (university or engineering school).\\n  * You love algorithms and coding.\\n  * You have an eye for detail, like a job well done, and don't fear code reviews.\\n  * You are very organized and can follow processes and practices carefully.\\n  * You can listen and handle direct feedback on all that you do.\\n  * You are highly committed to work and are not afraid of change.\\n  * You have excellent written and oral expression in English.\\n\\n  \\n\\nIn the first weeks, we will coach you intensively to improve your knowledge of\\nHexaly's products and acquire Hexaly's software development best practices.\\n\\n  \\n\\n**Your perks and benefits**\\n\\n  \\n\\nAnnual gross salary between €55,000 and €85,000 depending on profile and\\nexperience, plus various advantages (RTT, excellent healthcare insurance,\\nlunch, public transportation, coffee and tea, etc.).\\n\\n  \\n\\n**Recruitment process**\\n\\n  \\n\\n  * Remote interview with Julien, founder & Head of Science (30 minutes);\\n  * On-site assessment with 2 Senior Optimization Scientists (1 hour);\\n  * Welcome among us! A welcome breakfast with your future colleagues awaits you :-)\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"Hexaly is a fast-growing software company in Mathematical Optimization\"; \"We currently have 5 Senior Operations Research Scientist positions open\"; \"You have at least 5 years of experience in Mathematical Optimization\"; \"the fastest solver for Routing, Scheduling, Packing\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\"; \"You have excellent written and oral expression in English.\"',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"You have a Ph.D. or a Master\\'s in Operations Research, Computer Science, or Applied Mathematics (university or engineering school).\"',\n",
       "     'score': 1.5}],\n",
       "   'score': 4,\n",
       "   'time': 80.34622192382812},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': \"The job description states: 'Hexaly is a fast-growing software company in Mathematical Optimization, also known as Operations Research or Decision Science.' and 'You have at least 5 years of experience in Mathematical Optimization, preferably in business and industry.'\",\n",
       "     'score': 2},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': \"Location: Paris, Île-de-France, France. The job description is in English and states: 'You have excellent written and oral expression in English.'\",\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD)',\n",
       "     'evidence': \"The job description states: 'You have a Ph.D. or a Master's in Operations Research, Computer Science, or Applied Mathematics (university or engineering school).'\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'No such requirement is present; all required domains (optimization, algorithms, coding) are covered in the profile.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Requires a programming language I am not familiar with, AND does not mention Python',\n",
       "     'evidence': 'No programming language is specified as required, and the profile covers Python and general coding skills.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms',\n",
       "     'evidence': 'The job is focused on algorithms and optimization, not infrastructure.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Vague description of actual tasks for a data scientist/engineer job',\n",
       "     'evidence': 'The tasks are clearly described: developing features, algorithm improvements, bug fixes, user support, and turnkey application development.',\n",
       "     'score': 0},\n",
       "    {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "     'evidence': 'Optimization is mentioned in the context of mathematical optimization, not infrastructure.',\n",
       "     'score': 0},\n",
       "    {'criteria': \"'optimization' mentioned primarily in the context of quantum algorithms\",\n",
       "     'evidence': 'No mention of quantum algorithms.',\n",
       "     'score': 0},\n",
       "    {'criteria': \"Requires 'deep expertise' / 'senior-level experience' / 'mastery' of MLOps, large-scale training, or inference optimization (beyond just 'good fundamentals' or 'being comfortable')\",\n",
       "     'evidence': 'No such requirement is present; the focus is on mathematical optimization and algorithms.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'More managerial than technical role',\n",
       "     'evidence': 'The role is technical, not managerial.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Involves leading a team of highly qualified/experienced people (junior excluded)',\n",
       "     'evidence': 'No mention of team leadership; the role is as a member of the tech team.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Involves coaching world-class scientists',\n",
       "     'evidence': 'No such requirement is present.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "     'evidence': 'Hexaly is not a top-tier company by the given definition.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'No explicit mention of company size, but the description suggests a smaller, fast-growing company.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Offers a full-remote option',\n",
       "     'evidence': 'No mention of a full-remote option; the process includes an on-site assessment and a welcome breakfast.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Consulting job for a standard/low-tier consulting firm',\n",
       "     'evidence': 'Hexaly is a product company with professional services, not a standard consulting firm.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'In the defense sector',\n",
       "     'evidence': 'Hexaly is not in the defense sector.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'In the robotics sector',\n",
       "     'evidence': 'Hexaly is not in the robotics sector.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'If not french, requires security clearance',\n",
       "     'evidence': 'No mention of security clearance.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "     'evidence': 'No mention of Reinforcement Learning (RL) as a requirement.',\n",
       "     'score': 0},\n",
       "    {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "     'evidence': 'No mention of agentic workflows, langchain, or similar technologies.',\n",
       "     'score': 0}],\n",
       "   'score': 4.0,\n",
       "   'time': 10.983829021453857},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': '\"Hexaly is a fast-growing software company in Mathematical Optimization ... The team develops Hexaly Optimizer, the fastest solver for Routing, Scheduling, Packing, and more.\"; job title: \"Senior Operations Research Scientist\"',\n",
       "     'score': 2},\n",
       "    {'criteria': 'The job is based in France and the description is in English',\n",
       "     'evidence': 'Location: \"Paris, Île-de-France, France\"; job description text is in English',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a Ph.D. in a field close to mine (or even if it is just a plus) (explicitly mentioned)',\n",
       "     'evidence': '\"You have a Ph.D. or a Master\\'s in Operations Research, Computer Science, or Applied Mathematics (university or engineering school).\"',\n",
       "     'score': 1.5}],\n",
       "   'score': 4.0,\n",
       "   'time': 21.336983919143677},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "     'evidence': 'Hexaly is a fast-growing software company in Mathematical Optimization, also known as Operations Research or Decision Science. [...] We currently have 5 Senior Operations Research Scientist positions open at Hexaly. [...] You have at least 5 years of experience in Mathematical Optimization, preferably in business and industry.',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "     'evidence': 'location: Paris, Île-de-France, France [...] You have excellent written and oral expression in English.',\n",
       "     'score': 0.5},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': \"You have a Ph.D. or a Master's in Operations Research, Computer Science, or Applied Mathematics (university or engineering school).\",\n",
       "     'score': 1.5}],\n",
       "   'score': 4,\n",
       "   'time': 20.827021837234497}},\n",
       " {'id': 11,\n",
       "  'job_description': \"**Job Title:** Research Scientist – GC-MS/MS\\n\\n**Contract Type:** Full-Time Contract\\n\\n**Location:** North Ryde, Sydney\\n\\n**Clearance Required:** Australian Citizenship + Ability to Obtain Baseline\\nSecurity Clearance\\n\\n**Duration:** 12 months to commence mid-October – early November\\n\\n  \\n\\n**About the Opportunity**\\n\\nAn exciting opportunity is available for an experienced **Research Scientist\\nwith expertise in GC-MS/MS** to join a leading, WADA-accredited laboratory\\ninvolved in the testing and research of anti-doping samples for elite athletes\\nacross Australia, New Zealand, and beyond.\\n\\n  \\n\\nThis role forms part of a dynamic, high-performing team focused on delivering\\nworld-class scientific outcomes in a time-sensitive, quality-driven\\nenvironment. You will be based in **North Ryde, Sydney** , working with\\ncutting-edge instrumentation and contributing to innovative research and\\ndevelopment in anti-doping science.\\n\\n  \\n\\n**About You – Skills & Experience**\\n\\nThe ideal candidate will demonstrate:\\n\\n  * Proven experience in **method development** (eg, sample preparation/extraction, instrument optimisation) **and validation** of analytical techniques in biological samples (essential).\\n  * Strong hands-on expertise with **GC-MS/MS** , including maintenance, troubleshooting, and optimisation (essential).\\n  * Demonstrated experience with gas chromatography tandem mass spectrometry (GC-MSMS) applied to the analysis of small molecules\\n  * Ability to work independently on complex analyses, meet tight deadlines, and contribute to team goals (desirable).\\n  * Proficient communication skills and ability to document scientific work clearly (desirable).\\n  * Experience applying **statistical tools** in chemical/biochemical analysis (desirable).\\n  * Understanding of **ISO 17025 quality systems** in a laboratory setting (desirable).\\n\\n  \\n\\n**Key Responsibilities**\\n\\n  * **Method Development & Validation:** Assist in developing and validating analytical methods in biological matrices, focusing on GC-MS/MS technologies.\\n  * **Research Projects:** Manage and conduct analytical research projects, including data collation, statistical analysis, and reporting.\\n  * **Instrument Operation & Maintenance:** Operate, troubleshoot, and maintain GC-MS/MS instrumentation; assist in training colleagues as needed.\\n  * **Documentation & Reporting:** Accurately document observations and results; contribute to method reports and validation documentation.\\n  * **Scientific Literature Reviews:** Support the team by reviewing current scientific literature relevant to anti-doping and analytical chemistry.\\n\\n  \\n\\n**Qualifications & Eligibility**\\n\\n  * **Bachelors of Science** (Analytical Chemistry or similar) is essential.\\n  * **Minimum 5 years' experience** as a research scientist working with GC-MS/MS.\\n  * Postgraduate qualifications (Master’s or PhD) are highly desirable.\\n  * **Australian Citizenship** is mandatory.\\n  * Must be able to obtain and maintain a **Baseline security clearance**.\\n\\n  \\n\\n**Additional Information**\\n\\n  * Flexible working arrangements are available.\\n  * During major international sporting events, **shift work (including weekends and public holidays)** may be required.\\n\\n  \\n\\n**How to Apply**\\n\\nIf you’re a driven scientist passionate about high-integrity testing and\\nadvanced analytical chemistry, we encourage you to apply today with your CV\\noutlining your relevant experience.\\n\\nor email to ekta.ojha@persolapac.com\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': '“Strong hands-on expertise with GC-MS/MS, including maintenance, troubleshooting, and optimisation (essential).”',\n",
       "     'score': -2},\n",
       "    {'criteria': 'If not french, requires security clearance',\n",
       "     'evidence': '“Clearance Required: Australian Citizenship + Ability to Obtain Baseline Security Clearance.”',\n",
       "     'score': -1.5}],\n",
       "   'score': -3.5,\n",
       "   'time': 70.46337795257568},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences (-2 if this domain/tool is central to the role, defined as being in the job title, company name, or a primary responsibility/requirement; -1 if it is a secondary qualification).\",\n",
       "     'evidence': \"The job title is 'Research Scientist – GC-MS/MS' and the description repeatedly emphasizes required expertise in GC-MS/MS (gas chromatography tandem mass spectrometry), method development and validation in biological samples, and experience in anti-doping/analytical chemistry. These are not present in your profile, which is focused on AI, optimization, RL, and computer vision.\",\n",
       "     'score': -2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD): (+1.5)',\n",
       "     'evidence': 'Postgraduate qualifications (Master’s or PhD) are highly desirable.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'If not french, requires security clearance: (-1.5)',\n",
       "     'evidence': 'Clearance Required: Australian Citizenship + Ability to Obtain Baseline Security Clearance.',\n",
       "     'score': -1.5}],\n",
       "   'score': -2,\n",
       "   'time': 21.458253145217896},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Job Title: \"Research Scientist – GC-MS/MS\"; \"Strong hands-on expertise with GC-MS/MS, including maintenance, troubleshooting, and optimisation (essential).\"; \"Proven experience in method development (eg, sample preparation/extraction, instrument optimisation) and validation of analytical techniques in biological samples (essential).\"',\n",
       "     'score': -2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': '\"Postgraduate qualifications (Master’s or PhD) are highly desirable.\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'If not french, requires security clearance',\n",
       "     'evidence': '\"Australian Citizenship + Ability to Obtain Baseline Security Clearance\"; \"Must be able to obtain and maintain a Baseline security clearance.\"',\n",
       "     'score': -1.5}],\n",
       "   'score': -2,\n",
       "   'time': 26.78138494491577},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Strong hands-on expertise with GC-MS/MS, including maintenance, troubleshooting, and optimisation (essential).',\n",
       "     'score': -2.0},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Proven experience in method development (eg, sample preparation/extraction, instrument optimisation) and validation of analytical techniques in biological samples (essential).',\n",
       "     'score': -2.0},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "     'evidence': 'Understanding of ISO 17025 quality systems in a laboratory setting (desirable).',\n",
       "     'score': -1.0},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Postgraduate qualifications (Master’s or PhD) are highly desirable.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'If not french, requires security clearance',\n",
       "     'evidence': 'Australian Citizenship is mandatory. Must be able to obtain and maintain a Baseline security clearance.',\n",
       "     'score': -1.5}],\n",
       "   'score': -5,\n",
       "   'time': 21.411925077438354}},\n",
       " {'id': 12,\n",
       "  'job_description': \"At Google, we have a vision of empowerment and equitable opportunity for all\\nAboriginal and Torres Strait Islander peoples and commit to building\\nreconciliation through Google’s technology, platforms and people and we\\nwelcome Indigenous applicants. Please see our Reconciliation Action Plan for\\nmore information.  \\n  \\n**Minimum qualifications:  \\n  \\n**\\n\\n  * PhD degree in Computer Science, a related field, or equivalent practical experience.\\n  * One or more scientific publication submissions for conferences, journals, or public repositories (such as CVPR, ICCV, NeurIPS, ICML, ICLR, etc.).  \\n  \\n\\n**Preferred qualifications:  \\n  \\n**\\n\\n  * Experience in areas like face anti-spoofing, biometrics, 3D/2.5D vision, facial landmark/pose estimation.\\n  * Experience with TensorFlow, Flume, common computer vision libraries/frameworks and Android.\\n  * Interest to build production systems.\\n  * Excellent software engineering skills (e.g., C++, python, data processing, production backend development, etc.).  \\n  \\n\\n**About The Job  \\n  \\n** As an organization, Google maintains a portfolio of research projects\\ndriven by fundamental research, new product innovation, product contribution\\nand infrastructure goals, while providing individuals and teams the freedom to\\nemphasize specific types of work. As a Research Scientist, you'll setup large-\\nscale tests and deploy promising ideas quickly and broadly, managing deadlines\\nand deliverables while applying the latest theories to develop new and\\nimproved products, processes, or technologies. From creating experiments and\\nprototyping implementations to designing new architectures, our research\\nscientists work on real-world problems that span the breadth of computer\\nscience, such as machine (and deep) learning, data mining, natural language\\nprocessing, hardware and software performance analysis, improving compilers\\nfor mobile platforms, as well as core search and much more.  \\n  \\nAs a Research Scientist, you'll also actively contribute to the wider research\\ncommunity by sharing and publishing your findings, with ideas inspired by\\ninternal projects as well as from collaborations with research programs at\\npartner universities and technical institutes all over the world.  \\n  \\nIn this role, you will develop models and architectures grounded in foundation\\nmodels, data-efficient algorithms, and federated learning.  \\n  \\n**Responsibilities  \\n  \\n**\\n\\n  * Author research papers to share and generate impact of research results across the team and in the research community.\\n  * Help in growing research business across teams by sharing research trends and best practices within the community.\\n  * Define the data structure, framework, design, and evaluation metrics for research solution development and implementation under minimal guidance. Identify timelines and obtain resources needed.\\n  * Identify new and upcoming research areas by interacting with external and internal collaborators. Help in developing research strategy and plans to expand the impact of Google research with some guidance. \\n  * Contribute to conducting experiments based on the research question. Develop research prototypes or conduct simulations to further evaluate the impact of research, finalize hypotheses, and refine the research methodology under minimal guidance.  \\n  \\n  \\n\\nGoogle is proud to be an equal opportunity workplace and is an affirmative\\naction employer. We are committed to equal employment opportunity regardless\\nof race, color, ancestry, religion, sex, national origin, sexual orientation,\\nage, citizenship, marital status, disability, gender identity or Veteran\\nstatus. We also consider qualified applicants regardless of criminal\\nhistories, consistent with legal requirements. See also Google's EEO Policy\\nand EEO is the Law. If you have a disability or special need that requires\\naccommodation, please let us know by completing our Accommodations for\\nApplicants form .\\n\\nShow more  Show less\\n\\n\",\n",
       "  'oracle': {'evaluation_grid': [{'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Minimum qualifications: PhD degree in Computer Science, a related field, or equivalent practical experience.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'More than 150 employees',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': -1}],\n",
       "   'score': 2.5,\n",
       "   'time': 55.94720816612244},\n",
       "  'gpt-4.1': {'evaluation_grid': [{'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "     'evidence': 'Minimum qualifications: PhD degree in Computer Science, a related field, or equivalent practical experience.',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, etc.)',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': 2},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences (secondary qualification)\",\n",
       "     'evidence': 'Preferred qualifications: Experience in areas like face anti-spoofing, biometrics, 3D/2.5D vision, facial landmark/pose estimation. (Your profile does not mention experience in face anti-spoofing, biometrics, or facial landmark/pose estimation, which are secondary qualifications.)',\n",
       "     'score': -1},\n",
       "    {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences (secondary qualification)\",\n",
       "     'evidence': 'Preferred qualifications: Experience with TensorFlow, Flume, common computer vision libraries/frameworks and Android. (You have OpenCV and YOLOv8, but no mention of TensorFlow, Flume, or Android. These are secondary qualifications.)',\n",
       "     'score': -1}],\n",
       "   'score': 1.5,\n",
       "   'time': 11.846091985702515},\n",
       "  'gpt-5-mini': {'evaluation_grid': [{'criteria': 'Requires a PhD in a field close to mine (+1.5)',\n",
       "     'evidence': '\"PhD degree in Computer Science, a related field, or equivalent practical experience.\"',\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile (secondary qualification) (-1)',\n",
       "     'evidence': '\"Experience with TensorFlow, Flume, common computer vision libraries/frameworks and Android.\"',\n",
       "     'score': -1},\n",
       "    {'criteria': 'Top-tier company (Google) (+2)',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': 2},\n",
       "    {'criteria': 'Company >150 employees (-1)',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': -1}],\n",
       "   'score': 1.5,\n",
       "   'time': 27.367816925048828},\n",
       "  'gemini-2.5-flash': {'evaluation_grid': [{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences: (-2 if this domain/tool is central to the role, defined as being in the job title, company name, or a primary responsibility/requirement; -1 if it is a secondary qualification).\",\n",
       "     'evidence': \"Job Title: 'Research Scientist, Vision Language and Multimodal Modeling' - The profile has Computer Vision but not explicit Language and Multimodal Modeling expertise. Preferred qualifications: 'Experience in areas like face anti-spoofing, biometrics, 3D/2.5D vision, facial landmark/pose estimation.' - The profile has general Computer Vision but not these specific sub-domains. Preferred qualifications: 'Experience with TensorFlow, Flume, common computer vision libraries/frameworks and Android.' - The profile mentions PyTorch, JAX, OpenCV, but not explicitly Flume or Android.\",\n",
       "     'score': -4.0},\n",
       "    {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus) (has to be explicitly mentioned in the job description. Having experience leading research teams does not imply a PhD): (+1.5)',\n",
       "     'evidence': \"Minimum qualifications: 'PhD degree in Computer Science, a related field, or equivalent practical experience.'\",\n",
       "     'score': 1.5},\n",
       "    {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia): (+2) (Do not trust the description of the company in the job description for this criteria, but your prior knowledge about the company if any.)',\n",
       "     'evidence': 'company name: Google',\n",
       "     'score': 2.0},\n",
       "    {'criteria': 'More than 150 employees: (-1)',\n",
       "     'evidence': 'Google is a very large company.',\n",
       "     'score': -1.0}],\n",
       "   'score': -1.5,\n",
       "   'time': 37.50789189338684}}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1a2cb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_description</th>\n",
       "      <th>oracle</th>\n",
       "      <th>gpt-4.1</th>\n",
       "      <th>gpt-5-mini</th>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>evaluation_grid</th>\n",
       "      <td>11</td>\n",
       "      <td>**Job Title:** Research Scientist – GC-MS/MS\\n...</td>\n",
       "      <td>[{'criteria': 'Requires demonstrated expertise...</td>\n",
       "      <td>[{'criteria': 'Requires demonstrated expertise...</td>\n",
       "      <td>[{'criteria': 'Requires demonstrated expertise...</td>\n",
       "      <td>[{'criteria': 'Requires demonstrated expertise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>11</td>\n",
       "      <td>**Job Title:** Research Scientist – GC-MS/MS\\n...</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>11</td>\n",
       "      <td>**Job Title:** Research Scientist – GC-MS/MS\\n...</td>\n",
       "      <td>70.463378</td>\n",
       "      <td>21.458253</td>\n",
       "      <td>26.781385</td>\n",
       "      <td>21.411925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                    job_description  \\\n",
       "evaluation_grid  11  **Job Title:** Research Scientist – GC-MS/MS\\n...   \n",
       "score            11  **Job Title:** Research Scientist – GC-MS/MS\\n...   \n",
       "time             11  **Job Title:** Research Scientist – GC-MS/MS\\n...   \n",
       "\n",
       "                                                            oracle  \\\n",
       "evaluation_grid  [{'criteria': 'Requires demonstrated expertise...   \n",
       "score                                                         -3.5   \n",
       "time                                                     70.463378   \n",
       "\n",
       "                                                           gpt-4.1  \\\n",
       "evaluation_grid  [{'criteria': 'Requires demonstrated expertise...   \n",
       "score                                                           -2   \n",
       "time                                                     21.458253   \n",
       "\n",
       "                                                        gpt-5-mini  \\\n",
       "evaluation_grid  [{'criteria': 'Requires demonstrated expertise...   \n",
       "score                                                           -2   \n",
       "time                                                     26.781385   \n",
       "\n",
       "                                                  gemini-2.5-flash  \n",
       "evaluation_grid  [{'criteria': 'Requires demonstrated expertise...  \n",
       "score                                                           -5  \n",
       "time                                                     21.411925  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make df containing score and time for each model\n",
    "df = pd.DataFrame(results[10])\n",
    "# df = df[[\"model\", \"score\", \"time\"]]\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "481f3101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "  'evidence': 'Strong software-design instincts: testing, code review, CI/CD',\n",
       "  'score': -1.0},\n",
       " {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "  'evidence': 'you’ll build and optimise the large-scale learning systems',\n",
       "  'score': -3.0},\n",
       " {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "  'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "  'score': 0.5},\n",
       " {'criteria': 'Requires \"deep expertise\" / \"senior-level experience\" / \"mastery\" of MLOps, large-scale training, or inference optimization (beyond just \"good fundamentals\" or \"being comfortable\")',\n",
       "  'evidence': '4 + years working on large-scale ML codebases',\n",
       "  'score': -1.0},\n",
       " {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "  'evidence': 'Master’s or PhD in Computer Science (or equivalent proven track record)',\n",
       "  'score': 1.5},\n",
       " {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "  'evidence': 'company name: Mistral AI',\n",
       "  'score': 2.0},\n",
       " {'criteria': 'Offers a full-remote option',\n",
       "  'evidence': 'Location: Paris / London (hybrid) or remote from EU/UK',\n",
       "  'score': 2.0}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][\"gemini-2.5-flash\"][\"evaluation_grid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f004f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1:\n",
      "  Mean Absolute Error: 1.292\n",
      "  Average Time: 10.774s\n",
      "\n",
      "gpt-5-mini:\n",
      "  Mean Absolute Error: 1.792\n",
      "  Average Time: 31.905s\n",
      "\n",
      "gemini-2.5-flash:\n",
      "  Mean Absolute Error: 1.417\n",
      "  Average Time: 27.163s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute mean absolute error and average time for each model compared to oracle\n",
    "model_performance = {}\n",
    "\n",
    "for model_name in [\"gpt-4.1\", \"gpt-5-mini\", \"gemini-2.5-flash\"]:\n",
    "    mae_scores = []\n",
    "    times = []\n",
    "    \n",
    "    for result in results:\n",
    "        oracle_score = result[\"oracle\"][\"score\"]\n",
    "        model_score = result[model_name][\"score\"]\n",
    "        mae = abs(oracle_score - model_score)\n",
    "        mae_scores.append(mae)\n",
    "        times.append(result[model_name][\"time\"])\n",
    "    \n",
    "    model_performance[model_name] = {\n",
    "        \"mean_absolute_error\": sum(mae_scores) / len(mae_scores),\n",
    "        \"average_time\": sum(times) / len(times)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for model, metrics in model_performance.items():\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  Mean Absolute Error: {metrics['mean_absolute_error']:.3f}\")\n",
    "    print(f\"  Average Time: {metrics['average_time']:.3f}s\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a487cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job offer score variances (sorted by variance):\n",
      "==================================================\n",
      "Job ID: 7\n",
      "  Variance: 7.688\n",
      "  Scores: [-1.5, 3.5, 3.5, -2.5]\n",
      "\n",
      "Job ID: 4\n",
      "  Variance: 6.688\n",
      "  Scores: [6, 4, 2.0, 9]\n",
      "\n",
      "Job ID: 5\n",
      "  Variance: 6.562\n",
      "  Scores: [-1.5, 3, 4.5, 5]\n",
      "\n",
      "Job ID: 11\n",
      "  Variance: 2.250\n",
      "  Scores: [2.5, 1.5, 1.5, -1.5]\n",
      "\n",
      "Job ID: 10\n",
      "  Variance: 1.547\n",
      "  Scores: [-3.5, -2, -2, -5]\n",
      "\n",
      "Job ID: 2\n",
      "  Variance: 0.750\n",
      "  Scores: [-4, -4, -2, -4]\n",
      "\n",
      "Job ID: 1\n",
      "  Variance: 0.188\n",
      "  Scores: [2, 2, 2, 3]\n",
      "\n",
      "Job ID: 3\n",
      "  Variance: 0.188\n",
      "  Scores: [3, 3, 4, 3]\n",
      "\n",
      "Job ID: 8\n",
      "  Variance: 0.188\n",
      "  Scores: [1, 0, 1.0, 1]\n",
      "\n",
      "Job ID: 0\n",
      "  Variance: 0.172\n",
      "  Scores: [0, -0.5, -1, 0]\n",
      "\n",
      "Job ID: 6\n",
      "  Variance: 0.000\n",
      "  Scores: [1, 1, 1.0, 1]\n",
      "\n",
      "Job ID: 9\n",
      "  Variance: 0.000\n",
      "  Scores: [4, 4.0, 4.0, 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute variance in scores for each job offer\n",
    "job_variances = []\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    scores = [\n",
    "        result[\"oracle\"][\"score\"],\n",
    "        result[\"gpt-4.1\"][\"score\"],\n",
    "        result[\"gpt-5-mini\"][\"score\"],\n",
    "        result[\"gemini-2.5-flash\"][\"score\"]\n",
    "    ]\n",
    "    \n",
    "    # Calculate variance\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    variance = sum((score - mean_score) ** 2 for score in scores) / len(scores)\n",
    "    \n",
    "    job_variances.append({\n",
    "        \"job_id\": i,  # Assuming job_id corresponds to index in results\n",
    "        \"variance\": variance,\n",
    "        \"scores\": scores\n",
    "    })\n",
    "\n",
    "# Display results sorted by variance (highest first)\n",
    "job_variances_sorted = sorted(job_variances, key=lambda x: x[\"variance\"], reverse=True)\n",
    "\n",
    "print(\"Job offer score variances (sorted by variance):\")\n",
    "print(\"=\" * 50)\n",
    "for job in job_variances_sorted:\n",
    "    print(f\"Job ID: {job['job_id']}\")\n",
    "    print(f\"  Variance: {job['variance']:.3f}\")\n",
    "    print(f\"  Scores: {job['scores']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a5697c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a research engineer on our team, you will partner with research scientists\\nto turn research ideas into working systems; building the data, tooling, and\\ninfrastructure that enable rapid iteration, trustworthy evaluation, and a\\nsmooth path from prototype to production.  \\n  \\nBuilding on our proven track record of AI-powered solutions (e.g., Bits AI,\\nWatchdog, and Toto), Datadog AI Research is tackling high-risk, high-reward\\nprojects grounded in real-world challenges in cloud observability and\\nsecurity.  \\n  \\nWe are currently focused on three key research areas:  \\n  \\n\\n  * Observability Foundation Models – Building state-of-the-art models for advanced forecasting, anomaly detection, and multi-modal telemetry analysis (logs, metrics, traces, etc.). These models will also provide the foundation for our agents (described below) to natively analyze telemetry data. \\n  * Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments, pushing the boundaries of multi-step planning, reasoning, and domain-specific knowledge. \\n  * Production Code Repair Agents – Developing agents and models that leverage code, logs, runtime data, and other signals to identify, fix, and even preempt performance issues and security vulnerabilities in production code.   \\n  \\n\\n**What You’ll Do:  \\n  \\n**\\n\\n  * Build and operate datasets, training and evaluation pipelines, benchmarks, and internal tooling \\n  * Implement models, run experiments at scale, and profile for reliability, performance, and cost \\n  * Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery \\n  * Make the research stack observable, reproducible, and easier to use \\n  * Establish rigorous automated benchmarks and regression tests for forecasting, anomaly detection, multi-modal analysis, agents, and code repair tasks \\n  * Collaborate with Research Scientists, Product, and Engineering to integrate advanced AI capabilities into Datadog’s product ecosystem and to harden prototypes into reliable services \\n  * Contribute high-quality code, documentation, and open-source artifacts that enable the community and internal teams to reproduce, extend, and evaluate results   \\n  \\n\\n**Who You Are:  \\n  \\n**\\n\\n  * You have strong software engineering skills with experience in domains such as observability, SRE, or security \\n  * You have depth in distributed computing and ML systems for training and inference at scale; experience with Ray, Slurm, or similar frameworks is a plus \\n  * You are proficient in Python, familiar with a systems language (e.g., Rust, C++, or Go), and you are comfortable with modern cloud and data infrastructure \\n  * You have practical experience implementing and operating ML training and inference systems (e.g., PyTorch or JAX), including containerization, orchestration, and GPU acceleration \\n  * You are familiar with efficient training, fine-tuning, and inference techniques for large foundation models \\n  * You can explain design and performance trade-offs clearly to both technical and non-technical audiences \\n  * You have a strong interest in open-science and open-source contributions, including establishing rigorous benchmarks and sharing artifacts with the community   \\n  \\n\\n**Bonus Points:  \\n  \\n**\\n\\n  * You have a demonstrated ability to bridge cutting-edge research prototypes and real-world product applications, ideally with large foundation models, generative AI agents, or domain-specific LLM deployments \\n  * You are passionate about pushing the boundaries of AI while maintaining a strong focus on customer impact, scalability, and responsible deployment of new technologies \\n  * You have hands-on experience with GPU programming and optimization, including experience in CUDA \\n  * You have experience writing production data pipelines and applications \\n  * You have experience supporting or contributing to research publications   \\n  \\n\\n_Datadog values people from all walks of life. We understand not everyone will\\nmeet all the above qualifications on day one. That's okay. If you’re\\npassionate about AI Research and want to grow your skills, we encourage you to\\napply.  \\n  \\n_**Benefits and Growth:  \\n  \\n**\\n\\n  * Competitive global benefits \\n  * New hire stock equity (RSUs) and employee stock purchase plan (ESPP) \\n  * Opportunity to collaborate closely with colleagues across the Datadog offices in New York City and Paris \\n  * Opportunity to attend and present at conferences and meetups \\n  * Intra-departmental mentor and buddy program for in-house networking \\n  * An inclusive company culture, ability to join our Community Guilds (Datadog employee resource groups)   \\n  \\n\\n_Benefits and Growth listed above may vary based on the country of your\\nemployment and the nature of your employment with Datadog.  \\n  \\n_**About Datadog:  \\n  \\n** Datadog (NASDAQ: DDOG) is a global SaaS business, delivering a rare\\ncombination of growth and profitability. We are on a mission to break down\\nsilos and solve complexity in the cloud age by enabling digital\\ntransformation, cloud migration, and infrastructure monitoring of our\\ncustomers’ entire technology stacks. Built by engineers, for engineers,\\nDatadog is used by organizations of all sizes across a wide range of\\nindustries. Together, we champion professional development, diversity of\\nthought, innovation, and work excellence to empower continuous growth. Join\\nthe pack and become part of a collaborative, pragmatic, and thoughtful people-\\nfirst community where we solve tough problems, take smart risks, and celebrate\\none another. Learn more about #DatadogLife on Instagram, LinkedIn, and Datadog\\nLearning Center.  \\n  \\n**Equal Opportunity at Datadog:  \\n  \\n** Datadog is proud to offer equal employment opportunity to everyone\\nregardless of race, color, ancestry, religion, sex, national origin, sexual\\norientation, age, citizenship, marital status, disability, gender identity,\\nveteran status, and other characteristics protected by law. We also consider\\nqualified applicants regardless of criminal histories, consistent with legal\\nrequirements. Here are our Candidate Legal Notices for your reference.  \\n  \\nDatadog endeavors to make our Careers Page accessible to all users. If you\\nwould like to contact us regarding the accessibility of our website or need\\nassistance completing the application process, please complete this form. This\\nform is for accommodation requests only and cannot be used to inquire about\\nthe status of applications.  \\n  \\n**Privacy and AI Guidelines:  \\n  \\n** Any information you submit to Datadog as part of your application will be\\nprocessed in accordance with Datadog’s Applicant and Candidate Privacy Notice.\\nFor information on our AI policy, please visit Interviewing at Datadog AI\\nGuidelines.\\n\\nShow more  Show less\\n\\n\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[7][\"job_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4544d0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criteria': 'Explicitly mentions Reinforcement Learning (RL) as a key requirement or skill',\n",
       "  'evidence': \"The job description states: 'Orchestrate distributed training and distributed RL with Ray, including scheduling, scaling, and failure recovery.'\",\n",
       "  'score': 2},\n",
       " {'criteria': 'Mentions explicitly algorithmic/mathematical optimization (e.g., Operations Research, planning, combinatorial optimization, MILP)',\n",
       "  'evidence': 'The job description does not mention algorithmic/mathematical optimization, operations research, or related terms.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Agentic workflows (ie. langchain, tool use, prompt engineering, etc.) are part of the job',\n",
       "  'evidence': \"The job description includes: 'Site Reliability Engineering (SRE) Autonomous Agents – Creating AI agents to automatically detect, diagnose, and resolve incidents in production environments...' and 'Production Code Repair Agents – Developing agents and models...' This is about building AI agents, but does not mention agentic workflow frameworks (langchain, tool use, prompt engineering) explicitly. However, the focus on agents is strong, so +2 is justified.\",\n",
       "  'score': 2},\n",
       " {'criteria': \"Requires demonstrated expertise in a specific technical domain or toolset that is absent from my profile's listed skills and experiences\",\n",
       "  'evidence': 'The job requires proficiency in Python and familiarity with a systems language (e.g., Rust, C++, or Go). The profile mentions some exposure to C++ and Java, but not Rust or Go. However, Python is the main language, and the systems language is not central. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Requires a programming language I am not familiar with, AND does not mention Python',\n",
       "  'evidence': 'The job requires Python as the main language, which is present in the profile. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'More focused on infrastructure (databases, cloud, Docker) than on algorithms',\n",
       "  'evidence': 'The job description balances infrastructure (datasets, pipelines, distributed training) and algorithms (model implementation, research, agents). Not more focused on infrastructure than algorithms. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Vague description of actual tasks for a data scientist/engineer job',\n",
       "  'evidence': 'The job description is detailed and specific about tasks and responsibilities. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': \"'Optimization' mentioned primarily for performance/infrastructure (e.g., inference speed, cloud costs, MLOps)\",\n",
       "  'evidence': 'Optimization is mentioned in the context of reliability, performance, and cost, but not as the primary focus. The main focus is on research and building agents/models. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'The job is based in France and requires a good english level. If the description is in english and the job is based in France, this criterion is verified.',\n",
       "  'evidence': 'Location: Paris, Île-de-France, France. The job description is in English.',\n",
       "  'score': 0.5},\n",
       " {'criteria': 'More managerial than technical role',\n",
       "  'evidence': 'The role is technical, not managerial. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Involves leading a team of highly qualified/experienced people (junior excluded)',\n",
       "  'evidence': 'No mention of team leadership responsibilities. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Involves coaching world-class scientists',\n",
       "  'evidence': 'No mention of coaching world-class scientists. No penalty.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Top-tier company (e.g., Google, Apple, Meta, Helsing, Mistral AI, Perplexity, OpenAI, Anthropic, Nvidia)',\n",
       "  'evidence': 'Datadog is not considered a top-tier AI research company by the provided definition.',\n",
       "  'score': 0},\n",
       " {'criteria': 'More than 150 employees',\n",
       "  'evidence': 'Datadog is a global SaaS business, publicly traded (NASDAQ: DDOG), and has more than 150 employees.',\n",
       "  'score': -1},\n",
       " {'criteria': 'Offers a full-remote option',\n",
       "  'evidence': 'No mention of a full-remote option in the job description.',\n",
       "  'score': 0},\n",
       " {'criteria': 'Consulting job for a standard/low-tier consulting firm',\n",
       "  'evidence': 'Not a consulting job.',\n",
       "  'score': 0},\n",
       " {'criteria': 'In the defense sector',\n",
       "  'evidence': 'Not in the defense sector.',\n",
       "  'score': 0},\n",
       " {'criteria': 'In the robotics sector',\n",
       "  'evidence': 'Not in the robotics sector.',\n",
       "  'score': 0},\n",
       " {'criteria': 'If not french, requires security clearance',\n",
       "  'evidence': 'No mention of security clearance.',\n",
       "  'score': 0},\n",
       " {'criteria': \"Requires 'deep expertise' / 'senior-level experience' / 'mastery' of MLOps, large-scale training, or inference optimization (beyond just 'good fundamentals' or 'being comfortable')\",\n",
       "  'evidence': \"The job requires 'depth in distributed computing and ML systems for training and inference at scale', but does not use terms like 'deep expertise', 'senior-level', or 'mastery'. No penalty.\",\n",
       "  'score': 0},\n",
       " {'criteria': 'Requires a PhD in a field close to mine (or even if it is just a plus)',\n",
       "  'evidence': 'The job description does not explicitly mention a PhD as a requirement or a plus.',\n",
       "  'score': 0}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[7][\"gpt-4.1\"][\"evaluation_grid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62c5ed3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AryaXAI stands at the forefront of AI innovation, revolutionizing AI for\\nmission-critical businesses by building explainable, safe, and aligned systems\\nthat scale responsibly. Our mission is to create AI tools that empower\\nresearchers, engineers, and organizations to unlock AI's full potential while\\nmaintaining transparency and safety.  \\n  \\nOur team thrives on a shared passion for cutting-edge innovation,\\ncollaboration, and a relentless drive for excellence. At AryaXAI, everyone\\ncontributes hands-on to our mission in a flat organizational structure that\\nvalues curiosity, initiative, and exceptional performance.  \\n  \\nAs a research scientist at AryaXAI, you will be uniquely positioned in our\\nteam to work on very large-scale industry problems and push forward the\\nfrontiers of AI technologies. You will become a part of the unique atmosphere\\nwhere startup culture meets research innovation, with key outcomes of speed\\nand reliability.  \\n  \\n**Responsibilities  \\n  \\n**\\n\\n  * You'll work on advanced problems related to AI explainability, AI safety, and AI alignment.\\n  * You'll have flexibility in picking up the specialization areas within ML/DL and problem types that address the above challenges.\\n  * Create new techniques around ML Observability & Alignment.\\n  * Collaborate with MLEs and SDE to roll out the features and manage their quality until they are fully stable.\\n  * Create and maintain technical and product documentation.\\n  * Publish papers in open forums like arxiv and present in industry forums like ICLR NeurIPS etc.   \\n  \\n\\n**Qualifications  \\n  \\n**\\n\\n  * Has a solid academic background in concepts of machine learning or deep learning or reinforcement learning.\\n  * Master or Ph.D in key engineering topics like computer science or Mathematics is required\\n  * Should have published peer-reviewed papers or contributed to opensource tools\\n  * Hands-on experience in working with deep learning frameworks like Tensorflow, Pytorch etc\\n  * Enjoys working on various DL problems that involve using different types of training data sets - textual, tabular, categorical, images etc\\n  * Comfortable deploying code in cloud environments/on-premise environments.\\n  * Good fundamentals in MLOps and productionising ML models.\\n  * Prior experience on working on ML explainability methods - LRP, SHAPE, LIME, IG, CEM etc.\\n  * 2+ years of hands-on experience in Deep Learning or Machine Learning.\\n  * Hands-on experience in implementing techniques like Transformer models, GANs, Deep Learning, etc.\\n\\nShow more  Show less\\n\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_full_job(2)[\"description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3590db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706516d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.352s\n",
      "content='3^3 = 3 × 3 × 3 = 27.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 13, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CW79MQhsXMpd9R7dglCCOKEUpxRA6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--dfdd3897-7ce7-42ef-b79b-acdc48396e01-0' usage_metadata={'input_tokens': 13, 'output_tokens': 25, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\"\n",
    ")\n",
    "response = llm.invoke(\"What is 3^3?\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time:.3f}s\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296d5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.870s\n",
      "content=[{'type': 'text', 'text': '3^3 = 27\\n\\nBecause 3^3 means 3 × 3 × 3 = 9 × 3 = 27.', 'annotations': []}] additional_kwargs={'reasoning': {'id': 'rs_0ba0c05806d029a50069027a1887f48196802c049ed81abfe7', 'summary': [], 'type': 'reasoning'}} response_metadata={'id': 'resp_0ba0c05806d029a50069027a1768388196abbbc47396e30ffc', 'created_at': 1761770007.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_name': 'gpt-5-mini-2025-08-07'} id='msg_0ba0c05806d029a50069027a1904c08196a94855fadeba60b3' usage_metadata={'input_tokens': 13, 'output_tokens': 37, 'total_tokens': 50, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Define the reasoning settings\n",
    "reasoning = {\n",
    "    \"effort\": \"low\",  # 'low', 'medium', or 'high'\n",
    "    \"summary\": None,  # 'detailed', 'auto', or None\n",
    "}\n",
    "\n",
    "# Instantiate the model with these settings\n",
    "start_time = time.time()\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\",  # This feature is mentioned with reasoning models\n",
    "    reasoning=reasoning\n",
    ")\n",
    "\n",
    "# This invocation will now use 'low' reasoning effort\n",
    "response = llm.invoke(\"What is 3^3?\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time:.3f}s\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fc1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "job_id = 18\n",
    "job = load_full_job(job_id)\n",
    "job_description = job[\"description\"]\n",
    "job_title = job[\"title\"]\n",
    "company_name = job[\"company\"]\n",
    "location = job[\"location\"]\n",
    "\n",
    "reasoning = {\n",
    "    \"effort\": \"high\",  # 'low', 'medium', or 'high'\n",
    "    \"summary\": None,  # 'detailed', 'auto', or None\n",
    "}\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\",  # This feature is mentioned with reasoning models\n",
    "    reasoning=reasoning\n",
    ")\n",
    "# llm = get_llm(model)\n",
    "llm = llm.with_structured_output(JobReviewResponse)\n",
    "message = HumanMessage(\n",
    "    content=review_prompt.format(job_description=job_description, profil_pro=profil_pro, job_title=job_title, company_name=company_name, location=location)\n",
    ")\n",
    "response = llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
